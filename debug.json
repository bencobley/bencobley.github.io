{
    "Experience": {
        "TrueCircle": {
            "theme": "Experience",
            "hash": "TrueCircle",
            "title": "TrueCircle AI",
            "shorttitle": "TrueCircle",
            "date": "2021",
            "subtitle": "Design Engineer @ Early-Stage Startup",
            "duration": "One Year Full-Time",
            "location": "TrueCircle HQ, London",
            "thanks": "PH et al.",
            "text1": "<b>How can we leverage AI to improve plastic recovery in recycling facilities?</b> <a href='https://www.truecircle.ai/'>TrueCircle AI</a> is developing innovative computer vision hardware, retrofitted onto existing conveyor belts, that captures continuous footage of material streams and calculates <b>composition by weight in real-time with 95%+ accuracy</b>. The composition data is displayed in intuitive dashboards, enabling facilities to optimise their flow and prevent valuable recyclable material from going to waste.",
            "text2": "We joined forces with UK facilities to explore <b>data-driven optimisation of recycling processes</b>. Our target audience is Plant Managers, who are focussed on maintaining unreliable equipment and have limited time to make process improvements for better efficiency. They lacked the data to guide equipment upgrades or set the right price for recycled material. Existing solutions in the market were not accurate enough and <b> time-consuming/expensive </b> to set up. TrueCircle AI offers a simple and reliable solution to this problem.",
            "text3": "We started with the minimum viable implementation: a GoPro taped above a conveyor belt. Over the following year, we developed the hardware into a finished product. Working in a small, dynamic team enabled significant variety and responsibility in the role. Some highlights included: \n<ul><li>Launching TrueCircle\u2019s MVP hardware and leading the installation of an <b>initial pilot system at a UK recycling facility</b>.</li>\n  <li>Leading development of our 'second-gen' hardware</b>, eliminating key failure modes and saving \u00a31000s in maintenance costs.</li>\n  <li>Establishing processes to hand over system installations to a 3rd-party supplier, <b>proving scalability</b>; a key requirement for TrueCircle\u2019s Series A.</li>\n</ul>",
            "text4": "At the end of our first year, we launched an updated hardware product that can be <b>retrofitted in just a few hours, with zero upfront cost</b> for our customers. Our system sends instant alerts for operational issues and verifies material purity with <b>95%+ accuracy in over 30 facilities</b> internationally. This led to increased trust in material quality and a direct increase in revenue per tonne for customers. To further drive efficiency, TrueCircle introduced Trade. In this online marketplace, Plant Managers can <b>buy and sell material with purity verified by AI </b> for the first time.",
            "highlights": [
                "First full-time engineer on hardware team",
                "Launched MVP prototype into UK facility",
                "Scaled product to 30+ facilities internationally"
            ],
            "skills": [
                "<span class='skill'>Mechanical</span>",
                "<span class='skill'>Prototyping</span>",
                "<span class='skill'>Embedded systems</span>",
                "<span class='skill'>Strategy</span>"
            ],
            "media1": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/TrueCircle_1a.png'/></li>",
                "<li class='splide__slide'><img data-splide-lazy='static/img/TrueCircle_1b.png'/></li>"
            ],
            "media2": [
                "<li class='splide__slide' data-splide-html-video='static/img/TrueCircle_2.mp4'><img src='static/img/TrueCircle_2.png'></li>"
            ],
            "media3": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/TrueCircle_3a.png'/></li>",
                "<li class='splide__slide'><img data-splide-lazy='static/img/TrueCircle_3b.png'/></li>"
            ],
            "media4": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/TrueCircle_4a.png'/></li>",
                "<li class='splide__slide'><img data-splide-lazy='static/img/TrueCircle_4b.png'/></li>",
                "<li class='splide__slide'><img data-splide-lazy='static/img/TrueCircle_4c.png'/></li>"
            ],
            "body": [
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/TrueCircle_1a.png'/></li>",
                        "<li class='splide__slide'><img data-splide-lazy='static/img/TrueCircle_1b.png'/></li>"
                    ],
                    "<b>How can we leverage AI to improve plastic recovery in recycling facilities?</b> <a href='https://www.truecircle.ai/'>TrueCircle AI</a> is developing innovative computer vision hardware, retrofitted onto existing conveyor belts, that captures continuous footage of material streams and calculates <b>composition by weight in real-time with 95%+ accuracy</b>. The composition data is displayed in intuitive dashboards, enabling facilities to optimise their flow and prevent valuable recyclable material from going to waste."
                ],
                [
                    [
                        "<li class='splide__slide' data-splide-html-video='static/img/TrueCircle_2.mp4'><img src='static/img/TrueCircle_2.png'></li>"
                    ],
                    "We joined forces with UK facilities to explore <b>data-driven optimisation of recycling processes</b>. Our target audience is Plant Managers, who are focussed on maintaining unreliable equipment and have limited time to make process improvements for better efficiency. They lacked the data to guide equipment upgrades or set the right price for recycled material. Existing solutions in the market were not accurate enough and <b> time-consuming/expensive </b> to set up. TrueCircle AI offers a simple and reliable solution to this problem."
                ],
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/TrueCircle_3a.png'/></li>",
                        "<li class='splide__slide'><img data-splide-lazy='static/img/TrueCircle_3b.png'/></li>"
                    ],
                    "We started with the minimum viable implementation: a GoPro taped above a conveyor belt. Over the following year, we developed the hardware into a finished product. Working in a small, dynamic team enabled significant variety and responsibility in the role. Some highlights included: \n<ul><li>Launching TrueCircle\u2019s MVP hardware and leading the installation of an <b>initial pilot system at a UK recycling facility</b>.</li>\n  <li>Leading development of our 'second-gen' hardware</b>, eliminating key failure modes and saving \u00a31000s in maintenance costs.</li>\n  <li>Establishing processes to hand over system installations to a 3rd-party supplier, <b>proving scalability</b>; a key requirement for TrueCircle\u2019s Series A.</li>\n</ul>"
                ],
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/TrueCircle_4a.png'/></li>",
                        "<li class='splide__slide'><img data-splide-lazy='static/img/TrueCircle_4b.png'/></li>",
                        "<li class='splide__slide'><img data-splide-lazy='static/img/TrueCircle_4c.png'/></li>"
                    ],
                    "At the end of our first year, we launched an updated hardware product that can be <b>retrofitted in just a few hours, with zero upfront cost</b> for our customers. Our system sends instant alerts for operational issues and verifies material purity with <b>95%+ accuracy in over 30 facilities</b> internationally. This led to increased trust in material quality and a direct increase in revenue per tonne for customers. To further drive efficiency, TrueCircle introduced Trade. In this online marketplace, Plant Managers can <b>buy and sell material with purity verified by AI </b> for the first time."
                ]
            ]
        },
        "GoogleX": {
            "theme": "Experience",
            "hash": "GoogleX",
            "title": "Google X",
            "shorttitle": "Google X",
            "date": "2019",
            "subtitle": "Intern @ Google's Moonshot Factory",
            "duration": "Six Months Full-Time",
            "location": "Google X HQ, California",
            "thanks": "RM & RG.",
            "text1": "<b>How can we find radical solutions to some of the world's most intractable problems?</b> A paid six-month placement at <a href=\"https://x.company/\">Google X</a>; Alphabet's experimental R&D facility. X's 'moonshot' approach to problem-solving explores ambitious high-risk, high-reward projects. By taking a radical, outside-the-box thinking approach to engineering challenges, X aims to find new technologies with the potential to become the 'next Google'.",
            "text2": "I collaborated with an early-stage team to help prototype and evaluate a <b>novel sensor technology</b>. As the team's software dev, I built the data pipeline, from sensor interrogation to cloud upload for machine learning. I co-designed a custom PCB, building our first portable device with improved features, including a <b>4x size reduction</b>, modular expandability of up to 8x, <b>2.5x higher sensor resolution</b>, and a portable design with an intuitive user interface.",
            "text3": "Through my work with X, I filed two <a href=\"https://patents.google.com/?inventor=bennet+cobley&oq=bennet+cobley\">2 Patent Applications</a> as <b>primary author</b>, which are now in the public domain. The pending patents describe a gas sensing system consisting of multiple gas sensor modules, each specific to a set of target analytes. The system can select any subset of the modules to create varied combinations of gasses to <b>generate broader training data for a machine-learned model</b>. These gas sensors can be pre-sensitised to specific targets with the addition of a camera module.",
            "text4": "We (the sensor team) partnered with Google's Farming Robotics project, <a href=\"https://x.company/projects/mineral/\">Mineral</a>. I built the hardware and software integration to mount our sensors to the physical robot and interface with Mineral's <b>ROS robotics system</b>. The data was published to the ROS network in real-time, with the combined sensor readings and GPS information enabling <b>geo-located insights about the plant health and yield</b>.",
            "highlights": [
                "Championed an all-new hardware generation",
                "Collaborated on Mineral, Google's Farming Robot",
                "Filed 2 <a href=\"https://patents.google.com/?inventor=bennet+cobley&oq=bennet+cobley\"> Patent Applications</a>"
            ],
            "skills": [
                "<span class='skill'>Embedded systems</span>",
                "<span class='skill'>Python</span>",
                "<span class='skill'>Interfaces</span>",
                "<span class='skill'>PCB design</span>"
            ],
            "media1": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/GoogleX_1a.png'/></li>",
                "<li class='splide__slide'><img data-splide-lazy='static/img/GoogleX_1b.png'/></li>"
            ],
            "media2": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/GoogleX_2.png'/></li>"
            ],
            "media3": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/GoogleX_3.png'/></li>"
            ],
            "media4": [
                "<li class='splide__slide' data-splide-youtube='https://www.youtube.com/watch?v=lmxrRps7DnI'><img src='static/img/lmxrRps7DnI.png'></li>"
            ],
            "body": [
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/GoogleX_1a.png'/></li>",
                        "<li class='splide__slide'><img data-splide-lazy='static/img/GoogleX_1b.png'/></li>"
                    ],
                    "<b>How can we find radical solutions to some of the world's most intractable problems?</b> A paid six-month placement at <a href=\"https://x.company/\">Google X</a>; Alphabet's experimental R&D facility. X's 'moonshot' approach to problem-solving explores ambitious high-risk, high-reward projects. By taking a radical, outside-the-box thinking approach to engineering challenges, X aims to find new technologies with the potential to become the 'next Google'."
                ],
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/GoogleX_2.png'/></li>"
                    ],
                    "I collaborated with an early-stage team to help prototype and evaluate a <b>novel sensor technology</b>. As the team's software dev, I built the data pipeline, from sensor interrogation to cloud upload for machine learning. I co-designed a custom PCB, building our first portable device with improved features, including a <b>4x size reduction</b>, modular expandability of up to 8x, <b>2.5x higher sensor resolution</b>, and a portable design with an intuitive user interface."
                ],
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/GoogleX_3.png'/></li>"
                    ],
                    "Through my work with X, I filed two <a href=\"https://patents.google.com/?inventor=bennet+cobley&oq=bennet+cobley\">2 Patent Applications</a> as <b>primary author</b>, which are now in the public domain. The pending patents describe a gas sensing system consisting of multiple gas sensor modules, each specific to a set of target analytes. The system can select any subset of the modules to create varied combinations of gasses to <b>generate broader training data for a machine-learned model</b>. These gas sensors can be pre-sensitised to specific targets with the addition of a camera module."
                ],
                [
                    [
                        "<li class='splide__slide' data-splide-youtube='https://www.youtube.com/watch?v=lmxrRps7DnI'><img src='static/img/lmxrRps7DnI.png'></li>"
                    ],
                    "We (the sensor team) partnered with Google's Farming Robotics project, <a href=\"https://x.company/projects/mineral/\">Mineral</a>. I built the hardware and software integration to mount our sensors to the physical robot and interface with Mineral's <b>ROS robotics system</b>. The data was published to the ROS network in real-time, with the combined sensor readings and GPS information enabling <b>geo-located insights about the plant health and yield</b>."
                ]
            ]
        },
        "Dyson": {
            "theme": "Experience",
            "hash": "Dyson",
            "title": "Dyson",
            "shorttitle": "Dyson",
            "date": "2018",
            "subtitle": "Intern @ Dyson [New Product Development]",
            "duration": "Three Months Full-Time",
            "location": "Dyson HQ, Malmesbury",
            "thanks": "SH et al.",
            "text1": "<b>How can we rethink physical interactions on a product familiar for 20+ years? </b> A paid internship in Dyson's <a href=\"https://careers.dyson.com/en-gb/what-you-can-do/engineer/new-product-innovation/\">New Product Development</a> team. I addressed a design challenge related to an unreleased (confidential) product. As an intern, I was given ownership of part design from <b>concept generation to design for manufacture</b>. Presenting four solutions across various engineering risk levels, I reimagined the user interaction challenges. This project sharpened my digital and physical prototyping abilities but inspired me to seek out faster, more entrepreneurial working environments.",
            "highlights": [
                "Intro to Dyson's rigorous engineering process",
                "Ownership of feature on an unreleased product",
                "Offered return role at Dyson upon Graduation."
            ],
            "skills": [
                "<span class='skill'>Concept design</span>",
                "<span class='skill'>Prototyping</span>",
                "<span class='skill'>CAD & CAE</span>",
                "<span class='skill'>DFM & DFA</span>"
            ],
            "media1": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/Dyson_1.png'/></li>",
                "<li class='splide__slide'><img data-splide-lazy='static/img/Dyson_2.png'/></li>"
            ],
            "body": [
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/Dyson_1.png'/></li>",
                        "<li class='splide__slide'><img data-splide-lazy='static/img/Dyson_2.png'/></li>"
                    ],
                    "<b>How can we rethink physical interactions on a product familiar for 20+ years? </b> A paid internship in Dyson's <a href=\"https://careers.dyson.com/en-gb/what-you-can-do/engineer/new-product-innovation/\">New Product Development</a> team. I addressed a design challenge related to an unreleased (confidential) product. As an intern, I was given ownership of part design from <b>concept generation to design for manufacture</b>. Presenting four solutions across various engineering risk levels, I reimagined the user interaction challenges. This project sharpened my digital and physical prototyping abilities but inspired me to seek out faster, more entrepreneurial working environments."
                ]
            ]
        },
        "Brompton": {
            "theme": "Experience",
            "hash": "Brompton",
            "title": "Brompton",
            "shorttitle": "Brompton",
            "date": "2017",
            "subtitle": "Intern @ Brompton Bicycle",
            "duration": "Three Months Full-Time",
            "location": "Brompton HQ, London",
            "thanks": "WCS & WBA.",
            "text1": "<b>How can we reimagine the iconic Brompton Bicycle? </b> A paid internship at <a href=\"https://www.brompton.com/\">Brompton</a>. I joined a live project team challenged to develop a new Brompton product. As a group of three interns, we began with a blank sheet of paper and concluded with three <b>fully ridable (and foldable) prototype bikes</b> in just three months. This project kick-started my computational design and hands-on workshop skillset.",
            "text2": "The CEO was highly complimentary of our work, and the project was <b>approved for commercialisation</b> (currently confidential). I am told the product is still in development and will be released 'soon'. When released, it will be Brompton's <b>first new core product line in 40+ years</b>.",
            "highlights": [
                "Collaborating as part of an all-intern team",
                "Challenged to redesign iconic Brompton product",
                "Fabricated 3 prototype bikes in just 3 months"
            ],
            "skills": [
                "<span class='skill'>Mechanical</span>",
                "<span class='skill'>CAD & CAE</span>",
                "<span class='skill'>Fabrication</span>",
                "<span class='skill'>AM</span>"
            ],
            "media1": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/Brompton_1a.png'/></li>",
                "<li class='splide__slide'><img data-splide-lazy='static/img/Brompton_1b.png'/></li>"
            ],
            "media2": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/Brompton_2.png'/></li>"
            ],
            "body": [
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/Brompton_1a.png'/></li>",
                        "<li class='splide__slide'><img data-splide-lazy='static/img/Brompton_1b.png'/></li>"
                    ],
                    "<b>How can we reimagine the iconic Brompton Bicycle? </b> A paid internship at <a href=\"https://www.brompton.com/\">Brompton</a>. I joined a live project team challenged to develop a new Brompton product. As a group of three interns, we began with a blank sheet of paper and concluded with three <b>fully ridable (and foldable) prototype bikes</b> in just three months. This project kick-started my computational design and hands-on workshop skillset."
                ],
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/Brompton_2.png'/></li>"
                    ],
                    "The CEO was highly complimentary of our work, and the project was <b>approved for commercialisation</b> (currently confidential). I am told the product is still in development and will be released 'soon'. When released, it will be Brompton's <b>first new core product line in 40+ years</b>."
                ]
            ]
        }
    },
    "Education": {
        "Imperial": {
            "theme": "Education",
            "hash": "Imperial",
            "title": "Imperial College",
            "shorttitle": "Imperial",
            "date": "2020",
            "subtitle": "Design Engineering Master's Degree",
            "duration": "Four Years Full-Time",
            "location": "Dyson School of Design Engineering",
            "thanks": "WB et al.",
            "text1": "<b>How can a degree best teach engineering with design?</b> The <a href=\"https://www.imperial.ac.uk/design-engineering/\">Dyson School</a> is the newest engineering department at Imperial College. Design Engineering is a <b>highly creative discipline at the intersection of hardware and software</b>. The degree covers the fundamentals, with an emphasis on product development, technical innovation, user-centred design, and enterprise. 'T-shaped' skillsets are encouraged; I specialise in physical computing, robotics, interaction, and technical prototyping. Through DesEng, I found a love for building new things to solve hard problems.",
            "text2": "I demonstrated academic excellence over the 4-years, achieving the <b>highest overall degree result of the 2020 class</b> and placing on the Dean\u2019s List for Academic Excellence in '18/'19/'20 (top 10% of year). My robotics Group project team were awarded an <b>international robotics prize</b> at IROS 2022 for the Best Application Paper, for our work on a <a href=\"#Percussion\">medical percussion device</a>.  During the degree, I interned at <b>Google X, Dyson, and Brompton</b>. I particularly enjoyed teaching RPi/Arduino after being offered a paid Teaching Assistant role through top-of-class results in <i>Physical Computing</i>.",
            "highlights": [
                "Awarded Head of School Achievement Prize '20",
                "Dean\u2019s List for Academic Excellence '18/'19/'20",
                "IROS 2022 <a href='#Percussion'>Best Application Paper</a>"
            ],
            "skills": [
                "<span class='skill'>Design theory</span>",
                "<span class='skill'>Users</span>",
                "<span class='skill'>Engineering fundamentals</span>",
                "<span class='skill'>Innovation</span>",
                "<span class='skill'>Enterprise</span>"
            ],
            "media1": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/Imperial_1.png'/></li>"
            ],
            "media2": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/Imperial_2.png'/></li>"
            ],
            "body": [
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/Imperial_1.png'/></li>"
                    ],
                    "<b>How can a degree best teach engineering with design?</b> The <a href=\"https://www.imperial.ac.uk/design-engineering/\">Dyson School</a> is the newest engineering department at Imperial College. Design Engineering is a <b>highly creative discipline at the intersection of hardware and software</b>. The degree covers the fundamentals, with an emphasis on product development, technical innovation, user-centred design, and enterprise. 'T-shaped' skillsets are encouraged; I specialise in physical computing, robotics, interaction, and technical prototyping. Through DesEng, I found a love for building new things to solve hard problems."
                ],
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/Imperial_2.png'/></li>"
                    ],
                    "I demonstrated academic excellence over the 4-years, achieving the <b>highest overall degree result of the 2020 class</b> and placing on the Dean\u2019s List for Academic Excellence in '18/'19/'20 (top 10% of year). My robotics Group project team were awarded an <b>international robotics prize</b> at IROS 2022 for the Best Application Paper, for our work on a <a href=\"#Percussion\">medical percussion device</a>.  During the degree, I interned at <b>Google X, Dyson, and Brompton</b>. I particularly enjoyed teaching RPi/Arduino after being offered a paid Teaching Assistant role through top-of-class results in <i>Physical Computing</i>."
                ]
            ]
        }
    },
    "Publications": {
        "OnionBot": {
            "theme": "Publications",
            "hash": "OnionBot",
            "title": "OnionBot",
            "shorttitle": "OnionBot",
            "date": "2020",
            "subtitle": "[Open Source] Master's Thesis",
            "duration": "One Year Part-Time",
            "location": "Imperial College London",
            "thanks": "DB.",
            "text1": "<b>Can we augment routine cooking tasks using machine vision and robotics?</b> I designed my Master's project to further my understanding of ML at a prototype level. OnionBot is a robotic kitchen assistant designed to automate routine pan-cooking tasks. Born from a desire for a robot that can soften onions while I prepare other ingredients, the prototype showcases the ability to <b>cook a complete pasta & sauce recipe</b>. Inspired by a great video by the <a href=\"https://youtu.be/ydzJPeeMiMI\">Experiments by Google</a> team, I shot a film explaining OnionBot. It gained almost 10K views on <a href=\"https://www.youtube.com/watch?v=W4utRCyo5C4\">YouTube</a>, nearly 25% of the views of the Google video!",
            "text2": "<i>Industrial</i> automation technology could also augment <i>home</i> cooking by <b>reducing errors and supporting decision-making</b>. However, designing automation tech for the home is a unique challenge, requiring versatile tools instead of specialised machines. While robot arms could replicate human-kitchen interactions, they are too big and costly for home use. Cameras could act as multi-purpose sensors, but no suitable cooking image datasets are available. With OnionBot, I combined <b> automation and machine vision techniques </b> into a simple countertop robot. Watch the film on <a href=\"https://www.youtube.com/watch?v=W4utRCyo5C4\">YouTube</a>",
            "text3": "I chose to tackle <i>pan-cooking</i> tasks first. A Raspberry Pi camera and thermal camera are mounted above the stove to monitor cooking progress. A <a href=\"https://coral.ai/products/accelerator/\">Coral TPU</a> accelerates classification. A servo motor adjusts the power setting of the induction stove. The project aims to provide <b>automation <i>without</i> adding excessive complexity</b>; instead of replacing the chef, OnionBot augments the chef with multitasking superpowers. The human provides the 'actuation', enhanced by a touchscreen interface 'sous-chef' that offers instructions, reminders, and alerts. OnionBot watches the pan so that the chef can concentrate on culinary creativity. This <b>human-centred approach</b> is a novel concept in cooking robotics research. Read the Thesis on <a href=\"https://arxiv.org/pdf/2011.05039.pdf\">Arxiv</a>.",
            "text4": "Food image classifiers show poor results in real-world scenarios due to the complexity and variability of food images. OnionBot introduces two innovations: Firstly, the <b>fixed camera view above the stove provides a consistent environment</b> for capturing images. Secondly, instead of pursuing a general classification approach, OnionBot adopts a milestone-based method where only<b>key cooking events, 'milestones', are labelled</b> for each recipe. This simplifies the perception challenge by significantly reducing the classification scope (from 1000s to 10s). I created a <b>labelling interface</b> to easily build labelled cooking image datasets by manually selecting each milestone while cooking. I used Google AutoML for streamlined model training, enabling new recipe models to be trained with just a few clicks. Watch the film on <a href=\"https://www.youtube.com/watch?v=W4utRCyo5C4\">YouTube</a>",
            "text5": "The prototype highlights the potential for automation in home cooking but requires large training datasets to advance further. A fleet of OnionBot devices could crowd-source labelled pan-cooking image data. The fleet-generated dataset, including rich metadata, could drive new research into cooking with AI. <b>I open-sourced OnionBot</b> to encourage further research; Texas-based Hill Yu reached out to me; he has built an OnionBot prototype (pictured above) called <a href=\"https://www.kitchenautomatique.com/\">Kitchen Automatique</a> and fundraised $40K to <b>commercialise the idea</b>. Wishing Kitchen Automatique the best of luck!",
            "highlights": [
                "Read Thesis on <a href=\"https://arxiv.org/pdf/2011.05039.pdf\">Arxiv</a>",
                "Open-sourced on <a href=\"https://github.com/onionbot \">GitHub</a>",
                "Featured in <a href=\"static/img/MagPi101.pdf\">RPi Mag</a>",
                "~10K views on <a href=\"https://www.youtube.com/watch?v=W4utRCyo5C4\">YouTube</a>"
            ],
            "skills": [
                "<span class='skill'>Interaction</span>",
                "<span class='skill'>Algorithms</span>",
                "<span class='skill'>Computer vision</span>",
                "<span class='skill'>Research</span>",
                "<span class='skill'>Python</span>",
                "<span class='skill'>Front-end</span>"
            ],
            "media1": [
                "<li class='splide__slide' data-splide-youtube='https://www.youtube.com/watch?v=W4utRCyo5C4'><img src='static/img/W4utRCyo5C4.png'></li>"
            ],
            "media2": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/OnionBot_2a.png'/></li>",
                "<li class='splide__slide'><img data-splide-lazy='static/img/OnionBot_2b.png'/></li>"
            ],
            "media3": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/OnionBot_3.png'/></li>"
            ],
            "media4": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/OnionBot_4a.png'/></li>",
                "<li class='splide__slide'><img data-splide-lazy='static/img/OnionBot_4b.png'/></li>"
            ],
            "media5": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/OnionBot_5.png'/></li>"
            ],
            "body": [
                [
                    [
                        "<li class='splide__slide' data-splide-youtube='https://www.youtube.com/watch?v=W4utRCyo5C4'><img src='static/img/W4utRCyo5C4.png'></li>"
                    ],
                    "<b>Can we augment routine cooking tasks using machine vision and robotics?</b> I designed my Master's project to further my understanding of ML at a prototype level. OnionBot is a robotic kitchen assistant designed to automate routine pan-cooking tasks. Born from a desire for a robot that can soften onions while I prepare other ingredients, the prototype showcases the ability to <b>cook a complete pasta & sauce recipe</b>. Inspired by a great video by the <a href=\"https://youtu.be/ydzJPeeMiMI\">Experiments by Google</a> team, I shot a film explaining OnionBot. It gained almost 10K views on <a href=\"https://www.youtube.com/watch?v=W4utRCyo5C4\">YouTube</a>, nearly 25% of the views of the Google video!"
                ],
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/OnionBot_2a.png'/></li>",
                        "<li class='splide__slide'><img data-splide-lazy='static/img/OnionBot_2b.png'/></li>"
                    ],
                    "<i>Industrial</i> automation technology could also augment <i>home</i> cooking by <b>reducing errors and supporting decision-making</b>. However, designing automation tech for the home is a unique challenge, requiring versatile tools instead of specialised machines. While robot arms could replicate human-kitchen interactions, they are too big and costly for home use. Cameras could act as multi-purpose sensors, but no suitable cooking image datasets are available. With OnionBot, I combined <b> automation and machine vision techniques </b> into a simple countertop robot. Watch the film on <a href=\"https://www.youtube.com/watch?v=W4utRCyo5C4\">YouTube</a>"
                ],
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/OnionBot_3.png'/></li>"
                    ],
                    "I chose to tackle <i>pan-cooking</i> tasks first. A Raspberry Pi camera and thermal camera are mounted above the stove to monitor cooking progress. A <a href=\"https://coral.ai/products/accelerator/\">Coral TPU</a> accelerates classification. A servo motor adjusts the power setting of the induction stove. The project aims to provide <b>automation <i>without</i> adding excessive complexity</b>; instead of replacing the chef, OnionBot augments the chef with multitasking superpowers. The human provides the 'actuation', enhanced by a touchscreen interface 'sous-chef' that offers instructions, reminders, and alerts. OnionBot watches the pan so that the chef can concentrate on culinary creativity. This <b>human-centred approach</b> is a novel concept in cooking robotics research. Read the Thesis on <a href=\"https://arxiv.org/pdf/2011.05039.pdf\">Arxiv</a>."
                ],
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/OnionBot_4a.png'/></li>",
                        "<li class='splide__slide'><img data-splide-lazy='static/img/OnionBot_4b.png'/></li>"
                    ],
                    "Food image classifiers show poor results in real-world scenarios due to the complexity and variability of food images. OnionBot introduces two innovations: Firstly, the <b>fixed camera view above the stove provides a consistent environment</b> for capturing images. Secondly, instead of pursuing a general classification approach, OnionBot adopts a milestone-based method where only<b>key cooking events, 'milestones', are labelled</b> for each recipe. This simplifies the perception challenge by significantly reducing the classification scope (from 1000s to 10s). I created a <b>labelling interface</b> to easily build labelled cooking image datasets by manually selecting each milestone while cooking. I used Google AutoML for streamlined model training, enabling new recipe models to be trained with just a few clicks. Watch the film on <a href=\"https://www.youtube.com/watch?v=W4utRCyo5C4\">YouTube</a>"
                ],
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/OnionBot_5.png'/></li>"
                    ],
                    "The prototype highlights the potential for automation in home cooking but requires large training datasets to advance further. A fleet of OnionBot devices could crowd-source labelled pan-cooking image data. The fleet-generated dataset, including rich metadata, could drive new research into cooking with AI. <b>I open-sourced OnionBot</b> to encourage further research; Texas-based Hill Yu reached out to me; he has built an OnionBot prototype (pictured above) called <a href=\"https://www.kitchenautomatique.com/\">Kitchen Automatique</a> and fundraised $40K to <b>commercialise the idea</b>. Wishing Kitchen Automatique the best of luck!"
                ]
            ]
        },
        "Percussion": {
            "theme": "Publications",
            "hash": "Percussion",
            "title": "Medical Percussion",
            "shorttitle": "Percussion",
            "date": "2020",
            "subtitle": "Robotics Research \nGroup Project",
            "duration": "Three Months Part-Time",
            "location": "MORPH Robotics Lab Imperial College London",
            "thanks": "PZQ/OT/YT/TN.",
            "text1": "<b>Can we replicate an ancient medical diagnosis tool with modern technology?</b> What is Percussion? Medical percussion involves tapping the chest, back, and abdomen to assess the condition of underlying tissues based on the resulting acoustic response. <b>Despite its frequent use in medical diagnosis, percussion dynamics are not fully understood.</b> Experienced practitioners modify the percussion force and impulse by adjusting the stiffness in their elbow and wrist joints, but the correlation between these adjustments and the acoustic response remains underexplored. This project explored how robotics and ML could help standardise medical percussion examinations.",
            "text2": "Our Robotics Lab Group introduced a <b>novel robotic percussion device</b> designed to imitate the human percussion technique through a two-degree-of-freedom linkage mechanism with adjustable joint stiffness. The force profile of a medical student performing percussion was captured and used to inform the simulation of a mathematical model of the mechanism in MATLAB (above). This allowed for identifying the <b>optimal parameters to build a hardware prototype</b>. The device was evaluated on a silicone phantom tissue model, demonstrating a <b>force profile comparable to that of a human performer</b>, with reduced variability between successive percussion actions.",
            "text3": "I contributed to the <b>development and analysis of the initial robotic device</b>. Teammate Oliver Thompson outlines the device in the presentation below. Oli's presentation was awarded Best Presentation Overall at IROS RoPat20 Robot-Assisted Training For Primary Care Workshop.",
            "text4": "<b>My colleagues continued researching the topic after our graduation</b>. In their first experiment, the device used spectro-temporal analysis with 1-D Continuous Wavelet Transform (CWT) to identify hard nodules resembling lipomas in silicone phantom tissue. In their second experiment, Gaussian Mixture Modelling (GMM) and Neural Network (NN) predictive models were used to classify composite phantom tissue of varying density and thickness. The proposed device and methods achieved up to 97.5% accuracy in the classification of phantoms, indicating the potential for robotic solutions to <b>standardise and improve the accuracy of percussion</b> diagnostic procedures.  This paper was accepted for publication in <a href=\"https://ieeexplore.ieee.org/document/9830846/\">IEEE RA-L</a>.",
            "text5": "Pilar Zhang Qiu presented the paper at IROS2022 in Kyoto, Japan. We were thrilled to be awarded the <a href=\"https://iros2022.org/2022/10/30/award-winners/\">Best Application Paper Award</a>. This was all <b>thanks to my wonderful colleagues</b> Pilar Zhang Qiu, Jacob Tan, Oliver Thompson, and our supervisor, Prof Thrishantha Nanayakkara.",
            "highlights": [
                "Awarded Best Application Paper at <a href=\"https://iros2022.org/2022/10/30/award-winners/\">IROS 2022</a>",
                "Published in <a href=\"https://ieeexplore.ieee.org/document/9830846/\">IEEE RA-L</a> ",
                "Shared in the <a href=\"https://www.imperial.ac.uk/news/242295/imperial-engineering-students-awarded-international-robotics/\">Imperial Newsletter</a>"
            ],
            "skills": [
                "<span class='skill'>Mechanical design</span>",
                "<span class='skill'>AM</span>",
                "<span class='skill'>Simulation</span>",
                "<span class='skill'>Research</span>"
            ],
            "media1": [
                "<li class='splide__slide' data-splide-html-video='static/img/Percussion_1.mp4'><img src='static/img/Percussion_1.png'></li>"
            ],
            "media2": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/Percussion_2.png'/></li>"
            ],
            "media3": [
                "<li class='splide__slide' data-splide-html-video='static/img/Percussion_3.mp4'><img src='static/img/Percussion_3.png'></li>"
            ],
            "media4": [
                "<li class='splide__slide' data-splide-youtube='https://www.youtube.com/watch?v=fW7HsbtPrFo'><img src='static/img/fW7HsbtPrFo.png'></li>"
            ],
            "media5": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/Percussion_4.png'/></li>"
            ],
            "body": [
                [
                    [
                        "<li class='splide__slide' data-splide-html-video='static/img/Percussion_1.mp4'><img src='static/img/Percussion_1.png'></li>"
                    ],
                    "<b>Can we replicate an ancient medical diagnosis tool with modern technology?</b> What is Percussion? Medical percussion involves tapping the chest, back, and abdomen to assess the condition of underlying tissues based on the resulting acoustic response. <b>Despite its frequent use in medical diagnosis, percussion dynamics are not fully understood.</b> Experienced practitioners modify the percussion force and impulse by adjusting the stiffness in their elbow and wrist joints, but the correlation between these adjustments and the acoustic response remains underexplored. This project explored how robotics and ML could help standardise medical percussion examinations."
                ],
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/Percussion_2.png'/></li>"
                    ],
                    "Our Robotics Lab Group introduced a <b>novel robotic percussion device</b> designed to imitate the human percussion technique through a two-degree-of-freedom linkage mechanism with adjustable joint stiffness. The force profile of a medical student performing percussion was captured and used to inform the simulation of a mathematical model of the mechanism in MATLAB (above). This allowed for identifying the <b>optimal parameters to build a hardware prototype</b>. The device was evaluated on a silicone phantom tissue model, demonstrating a <b>force profile comparable to that of a human performer</b>, with reduced variability between successive percussion actions."
                ],
                [
                    [
                        "<li class='splide__slide' data-splide-html-video='static/img/Percussion_3.mp4'><img src='static/img/Percussion_3.png'></li>"
                    ],
                    "I contributed to the <b>development and analysis of the initial robotic device</b>. Teammate Oliver Thompson outlines the device in the presentation below. Oli's presentation was awarded Best Presentation Overall at IROS RoPat20 Robot-Assisted Training For Primary Care Workshop."
                ],
                [
                    [
                        "<li class='splide__slide' data-splide-youtube='https://www.youtube.com/watch?v=fW7HsbtPrFo'><img src='static/img/fW7HsbtPrFo.png'></li>"
                    ],
                    "<b>My colleagues continued researching the topic after our graduation</b>. In their first experiment, the device used spectro-temporal analysis with 1-D Continuous Wavelet Transform (CWT) to identify hard nodules resembling lipomas in silicone phantom tissue. In their second experiment, Gaussian Mixture Modelling (GMM) and Neural Network (NN) predictive models were used to classify composite phantom tissue of varying density and thickness. The proposed device and methods achieved up to 97.5% accuracy in the classification of phantoms, indicating the potential for robotic solutions to <b>standardise and improve the accuracy of percussion</b> diagnostic procedures.  This paper was accepted for publication in <a href=\"https://ieeexplore.ieee.org/document/9830846/\">IEEE RA-L</a>."
                ],
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/Percussion_4.png'/></li>"
                    ],
                    "Pilar Zhang Qiu presented the paper at IROS2022 in Kyoto, Japan. We were thrilled to be awarded the <a href=\"https://iros2022.org/2022/10/30/award-winners/\">Best Application Paper Award</a>. This was all <b>thanks to my wonderful colleagues</b> Pilar Zhang Qiu, Jacob Tan, Oliver Thompson, and our supervisor, Prof Thrishantha Nanayakkara."
                ]
            ]
        }
    },
    "Projects": {
        "Dome": {
            "theme": "Projects",
            "hash": "Dome",
            "title": "Geodesic Dome",
            "shorttitle": "Dome",
            "date": "2022",
            "subtitle": "Passion Project",
            "duration": "Evenings & Weekends",
            "location": "Home",
            "thanks": "ZK et al.",
            "text1": "<b>Can we become self-sufficient by growing vegetables in a (futuristic) greenhouse? </b>After the success of <a href=\"#FarmBot\">FarmBot</a>, we built a geodesic dome greenhouse for propagation and overwintering vegetable plants. Built using a <a href=\"https://buildwithhubs.co.uk/\">Hubs</a> geodesic frame, kit with a custom polycarbonate glazing + 3D printed solution. Design spec: Icosahedron, Frequency 2, Subdivision class I, 3/4 Sphere (with flat base). <a href=\"https://acidome.com/lab/calc/#Flat_3/4_Piped_D88_2V_R1.606_beams_38x19\">3D model</a>",
            "highlights": [
                "60 polycarbonate panels in 3 different sizes",
                "35 glazing hubs 3D printed in clear PETG",
                "95 wooden struts in 3 different lengths",
                "There is a reason people build in rectangles!"
            ],
            "skills": [
                "<span class='skill'>CAD</span>",
                "<span class='skill'>Fabrication</span>",
                "<span class='skill'>Raspberry Pi</span>",
                "<span class='skill'>3D printing</span>"
            ],
            "media1": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/Dome_1a.png'/></li>",
                "<li class='splide__slide'><img data-splide-lazy='static/img/Dome_1b.png'/></li>",
                "<li class='splide__slide'><img data-splide-lazy='static/img/Dome_1c.png'/></li>",
                "<li class='splide__slide'><img data-splide-lazy='static/img/Dome_1d.png'/></li>"
            ],
            "body": [
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/Dome_1a.png'/></li>",
                        "<li class='splide__slide'><img data-splide-lazy='static/img/Dome_1b.png'/></li>",
                        "<li class='splide__slide'><img data-splide-lazy='static/img/Dome_1c.png'/></li>",
                        "<li class='splide__slide'><img data-splide-lazy='static/img/Dome_1d.png'/></li>"
                    ],
                    "<b>Can we become self-sufficient by growing vegetables in a (futuristic) greenhouse? </b>After the success of <a href=\"#FarmBot\">FarmBot</a>, we built a geodesic dome greenhouse for propagation and overwintering vegetable plants. Built using a <a href=\"https://buildwithhubs.co.uk/\">Hubs</a> geodesic frame, kit with a custom polycarbonate glazing + 3D printed solution. Design spec: Icosahedron, Frequency 2, Subdivision class I, 3/4 Sphere (with flat base). <a href=\"https://acidome.com/lab/calc/#Flat_3/4_Piped_D88_2V_R1.606_beams_38x19\">3D model</a>"
                ]
            ]
        },
        "Inky": {
            "theme": "Projects",
            "hash": "Inky",
            "title": "Inky for Spotify",
            "shorttitle": "Inky",
            "date": "2021",
            "subtitle": "Passion Project",
            "duration": "Evenings & Weekends",
            "location": "Home",
            "thanks": "TC.",
            "text1": "<b>Can we bring back the magic of album art in the digital music era?</b> Use a Raspberry Pi to display album art for your current Spotify listens on a 7-colour ePaper display. Designed for use with an Inky Impression 7 colour ePaper display. The ePaper display transitions bring the album art to life and doesn't require power to maintain the image! Check it out on <a href=\"https://github.com/tomcobley/inky-spotify\">GitHub</a>",
            "highlights": [
                "View your digital album art in a beautiful frame!",
                "7-colour low energy ePaper display",
                "Check the project out on <a href=\"https://github.com/tomcobley/inky-spotify\">GitHub</a>"
            ],
            "skills": [
                "<span class='skill'>Raspberry Pi</span>",
                "<span class='skill'>Python</span>",
                "<span class='skill'>APIs</span>"
            ],
            "media1": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/Inky_2.gif'/></li>"
            ],
            "body": [
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/Inky_2.gif'/></li>"
                    ],
                    "<b>Can we bring back the magic of album art in the digital music era?</b> Use a Raspberry Pi to display album art for your current Spotify listens on a 7-colour ePaper display. Designed for use with an Inky Impression 7 colour ePaper display. The ePaper display transitions bring the album art to life and doesn't require power to maintain the image! Check it out on <a href=\"https://github.com/tomcobley/inky-spotify\">GitHub</a>"
                ]
            ]
        },
        "FarmBot": {
            "theme": "Projects",
            "hash": "FarmBot",
            "title": "FarmBot",
            "shorttitle": "FarmBot",
            "date": "2021",
            "subtitle": "Passion Project",
            "duration": "Evenings & Weekends",
            "location": "Home",
            "thanks": "ZK et al.",
            "text1": "<b>Can we become self-sufficient by automating vegetable growing with robotics? </b><a href=\"https://farm.bot/\">FarmBot</a> is an <b>open-source, automated farming robot</b> for growing food using precision agriculture techniques developed by a team in California. We built the raised bed, assembled the kit, and programme the growing schedule. Changeable toolheads on a CNC cartesian gantry system allow FarmBot to sow seeds, water plants and destroy weeds automatically.",
            "text2": "This was a lockdown project motivated by the desire to be <b>more self-sufficient</b> by growing our own food. While FarmBot probably won't save money or time, net, over its lifetime, it did get us into vegetable growing! We had a great crop in the first year, but <b>90% of the credit goes to the humans</b> looking after FarmBot.",
            "highlights": [
                "Automated sowing!",
                "Automated watering!",
                "Automated weeding!"
            ],
            "skills": [
                "<span class='skill'>Fabrication</span>",
                "<span class='skill'>Horticulture</span>"
            ],
            "media1": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/FarmBot_1a.png'/></li>",
                "<li class='splide__slide'><img data-splide-lazy='static/img/FarmBot_1b.png'/></li>",
                "<li class='splide__slide'><img data-splide-lazy='static/img/FarmBot_1c.png'/></li>",
                "<li class='splide__slide'><img data-splide-lazy='static/img/FarmBot_1d.png'/></li>"
            ],
            "media2": [
                "<li class='splide__slide' data-splide-html-video='static/img/Farmbot_2a.mp4'><img src='static/img/Farmbot_2a.png'></li>",
                "<li class='splide__slide' data-splide-html-video='static/img/Farmbot_2b.mp4'><img src='static/img/Farmbot_2b.png'></li>"
            ],
            "body": [
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/FarmBot_1a.png'/></li>",
                        "<li class='splide__slide'><img data-splide-lazy='static/img/FarmBot_1b.png'/></li>",
                        "<li class='splide__slide'><img data-splide-lazy='static/img/FarmBot_1c.png'/></li>",
                        "<li class='splide__slide'><img data-splide-lazy='static/img/FarmBot_1d.png'/></li>"
                    ],
                    "<b>Can we become self-sufficient by automating vegetable growing with robotics? </b><a href=\"https://farm.bot/\">FarmBot</a> is an <b>open-source, automated farming robot</b> for growing food using precision agriculture techniques developed by a team in California. We built the raised bed, assembled the kit, and programme the growing schedule. Changeable toolheads on a CNC cartesian gantry system allow FarmBot to sow seeds, water plants and destroy weeds automatically."
                ],
                [
                    [
                        "<li class='splide__slide' data-splide-html-video='static/img/Farmbot_2a.mp4'><img src='static/img/Farmbot_2a.png'></li>",
                        "<li class='splide__slide' data-splide-html-video='static/img/Farmbot_2b.mp4'><img src='static/img/Farmbot_2b.png'></li>"
                    ],
                    "This was a lockdown project motivated by the desire to be <b>more self-sufficient</b> by growing our own food. While FarmBot probably won't save money or time, net, over its lifetime, it did get us into vegetable growing! We had a great crop in the first year, but <b>90% of the credit goes to the humans</b> looking after FarmBot."
                ]
            ]
        },
        "Campervan": {
            "theme": "Projects",
            "hash": "Campervan",
            "title": "Campervan conversion",
            "shorttitle": "Campervan",
            "date": "2020",
            "subtitle": "Passion Project",
            "duration": "Six Months Full-Time",
            "location": "Home",
            "thanks": "CW/HB/DC et al.",
            "text1": "<b>Can we rethink the typical van conversion and design a layout that is comfortable for 4 guests?</b>\nInspired by a love of the outdoors, I embarked on a campervan conversion project with friends during our year off (to help get out more). We took an unusual approach to typical van conversions, opting for an <b>aluminium extrusion frame</b> wrapped in lightweight plywood. Sleeping four comfortably meant thinking outside the box. We had three design goals:\n<ul>\n  <li>Four berths and four seats, comfortably.</li>\n  <li>Switching from day to night mode should take seconds, not minutes.</li>\n  <li>We won't get it 100% right first time, so everything should be removable</li>\n</ul>",
            "text2": "We created a <b>first-of-its-kind</b> (as far as we know) bed sliding mechanism to allow us to include both <b>four berths and four seats</b>, comfortably. The top bed slides over the kitchen area when 'night mode' is deployed. The end result is extremely comfortable, but comes with a significant increase in complexity. Check out the assembly timelapse and demonstration in the video below!",
            "text3": "For power, I built a fully off-grid solar system, so that the van never needs to be plugged in. I learnt how to spec solar panels, batteries, controllers etc. through online tutorials and <b>assembled the system myself</b> (see timelapse above). Specs:\n\n<ul>\n  <li>1200W Inverter for 240V mains power</li>\n  <li>100Ah 12V Lithium battery</li>\n  <li>440W Domestic Solar Panel</li>\n  <li>30A charger from vehicle alternator</li>\n  <li>Bluetooth connectivity to phone application</li>\n  <li>LED lights, 12V phone chargers, fridge, water pump etc.</li>\n</ul>\n\nBuilding a campervan was extremely fulflling, but far more of a time investment than I could ever have imagined. <b>Proceed with caution!</b>",
            "highlights": [
                "Personal project with friends during our year off",
                "Unique custom-designed bed mechanism",
                "All DIY: wood/metalwork, electrics and plumbing"
            ],
            "skills": [
                "<span class='skill'>CAD</span>",
                "<span class='skill'>Fabrication</span>",
                "<span class='skill'>3D printing</span>",
                "<span class='skill'>Electrical</span>",
                "<span class='skill'>Plumbing</span>",
                "<span class='skill'>Gas</span>"
            ],
            "media1": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/Campervan_1.png'/></li>"
            ],
            "media2": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/Campervan_2.png'/></li>"
            ],
            "media3": [
                "<li class='splide__slide' data-splide-youtube='https://www.youtube.com/watch?v=Ocdxqeg01c4'><img src='static/img/Ocdxqeg01c4.png'></li>"
            ],
            "media4": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/Campervan_3a.png'/></li>",
                "<li class='splide__slide'><img data-splide-lazy='static/img/Campervan_3b.png'/></li>",
                "<li class='splide__slide'><img data-splide-lazy='static/img/Campervan_3c.png'/></li>",
                "<li class='splide__slide'><img data-splide-lazy='static/img/Campervan_3d.png'/></li>",
                "<li class='splide__slide'><img data-splide-lazy='static/img/Campervan_3e.png'/></li>",
                "<li class='splide__slide'><img data-splide-lazy='static/img/Campervan_3f.png'/></li>",
                "<li class='splide__slide'><img data-splide-lazy='static/img/Campervan_3g.png'/></li>",
                "<li class='splide__slide'><img data-splide-lazy='static/img/Campervan_3h.png'/></li>"
            ],
            "body": [
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/Campervan_1.png'/></li>"
                    ],
                    "<b>Can we rethink the typical van conversion and design a layout that is comfortable for 4 guests?</b>\nInspired by a love of the outdoors, I embarked on a campervan conversion project with friends during our year off (to help get out more). We took an unusual approach to typical van conversions, opting for an <b>aluminium extrusion frame</b> wrapped in lightweight plywood. Sleeping four comfortably meant thinking outside the box. We had three design goals:\n<ul>\n  <li>Four berths and four seats, comfortably.</li>\n  <li>Switching from day to night mode should take seconds, not minutes.</li>\n  <li>We won't get it 100% right first time, so everything should be removable</li>\n</ul>"
                ],
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/Campervan_2.png'/></li>"
                    ],
                    "We created a <b>first-of-its-kind</b> (as far as we know) bed sliding mechanism to allow us to include both <b>four berths and four seats</b>, comfortably. The top bed slides over the kitchen area when 'night mode' is deployed. The end result is extremely comfortable, but comes with a significant increase in complexity. Check out the assembly timelapse and demonstration in the video below!"
                ],
                [
                    [
                        "<li class='splide__slide' data-splide-youtube='https://www.youtube.com/watch?v=Ocdxqeg01c4'><img src='static/img/Ocdxqeg01c4.png'></li>"
                    ],
                    "For power, I built a fully off-grid solar system, so that the van never needs to be plugged in. I learnt how to spec solar panels, batteries, controllers etc. through online tutorials and <b>assembled the system myself</b> (see timelapse above). Specs:\n\n<ul>\n  <li>1200W Inverter for 240V mains power</li>\n  <li>100Ah 12V Lithium battery</li>\n  <li>440W Domestic Solar Panel</li>\n  <li>30A charger from vehicle alternator</li>\n  <li>Bluetooth connectivity to phone application</li>\n  <li>LED lights, 12V phone chargers, fridge, water pump etc.</li>\n</ul>\n\nBuilding a campervan was extremely fulflling, but far more of a time investment than I could ever have imagined. <b>Proceed with caution!</b>"
                ]
            ]
        }
    }
}