{
    "Experience": {
        "TrueCircle": {
            "theme": "Experience",
            "hash": "TrueCircle",
            "title": "TrueCircle AI",
            "shorttitle": "TrueCircle",
            "date": "2021",
            "subtitle": "Design Engineer @ Early-Stage Startup",
            "duration": "One Year Full-Time",
            "location": "TrueCircle HQ, London",
            "thanks": "PH et al.",
            "text1": "<a href='https://www.truecircle.ai/'>TrueCircle AI</a> is a <b>climate-tech startup</b> that aims to revolutionize material recovery in recycling facilities. Our innovative computer vision hardware, retrofitted onto industrial cameras above conveyor belts, captures continuous footage of material streams and calculates their <b>composition by weight in real-time</b> with a 95%+ accuracy. The composition data is displayed in industry-leading dashboards, enabling facilities to run more efficiently and <b>prevent valuable recyclable material from going to waste</b>.",
            "text2": "We joined forces with UK facilities to develop <b>data-driven optimisation of recycling processes</b>. Our target audience is Plant Managers, who are focussed on maintaining unreliable equipment and have limited time to make process improvements for better efficiency. They lacked the data to guide the right equipment upgrades or set the right price for their recycled material. Existing solutions in the market were not accurate enough and required a <b>time-consuming and expensive</b> setup process. TrueCircle AI offered a simple and reliable solution to this problem.",
            "text3": "In the first year, we launched a revolutionary hardware product that can be easily <b>retrofitted in just a few hours, with zero upfront cost</b> for our customers. Our system sends instant alerts for operational issues and verifies material purity with <b>95%+ accuracy in over 30 facilities</b> worldwide. This has led to increased trust in material quality and a direct increase in revenue per tonne. To further drive efficiency, TrueCircle also introduced Trade. In this online marketplace, Plant Managers can <b>buy and sell material verified by our AI vision system</b> using purity data for the first time.",
            "text4": "<b>My impact on the team:</b>\n<ul>\n  <li>Launched TrueCircle\u2019s MVP hardware and led the installation of an <b>initial pilot system at a UK recycling facility</b>.</li>\n  <li>Outlined roadmap for reducing failure rate. Implemented strategy and <b>led development of new hardware version</b>, eliminating key failure modes and saving \u00a31000s in maintenance.</li>\n  <li>Demonstrated technical leadership; established processes to hand over system installations to a 3rd-party supplier, <b>proving scalability</b>; a key requirement for TrueCircle\u2019s Series A.</li>\n</ul>",
            "highlights": [
                "First full-time engineer on hardware team",
                "Launched MVP product in UK facility",
                "Scaled to 30+ facilities internationally"
            ],
            "media1": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/TrueCircle_1.png'/></li>"
            ],
            "media2": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/TrueCircle_2a.png'/></li>",
                "<li class='splide__slide'><img data-splide-lazy='static/img/TrueCircle_2b.png'/></li>",
                "<li class='splide__slide'><img data-splide-lazy='static/img/TrueCircle_2c.png'/></li>"
            ],
            "media3": [
                "<li class='splide__slide' data-splide-html-video='static/img/TrueCircle_3.mp4'><img src='static/img/TrueCircle_3.png'></li>"
            ],
            "media4": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/TrueCircle_4.png'/></li>"
            ],
            "body": [
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/TrueCircle_1.png'/></li>"
                    ],
                    "<a href='https://www.truecircle.ai/'>TrueCircle AI</a> is a <b>climate-tech startup</b> that aims to revolutionize material recovery in recycling facilities. Our innovative computer vision hardware, retrofitted onto industrial cameras above conveyor belts, captures continuous footage of material streams and calculates their <b>composition by weight in real-time</b> with a 95%+ accuracy. The composition data is displayed in industry-leading dashboards, enabling facilities to run more efficiently and <b>prevent valuable recyclable material from going to waste</b>."
                ],
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/TrueCircle_2a.png'/></li>",
                        "<li class='splide__slide'><img data-splide-lazy='static/img/TrueCircle_2b.png'/></li>",
                        "<li class='splide__slide'><img data-splide-lazy='static/img/TrueCircle_2c.png'/></li>"
                    ],
                    "We joined forces with UK facilities to develop <b>data-driven optimisation of recycling processes</b>. Our target audience is Plant Managers, who are focussed on maintaining unreliable equipment and have limited time to make process improvements for better efficiency. They lacked the data to guide the right equipment upgrades or set the right price for their recycled material. Existing solutions in the market were not accurate enough and required a <b>time-consuming and expensive</b> setup process. TrueCircle AI offered a simple and reliable solution to this problem."
                ],
                [
                    [
                        "<li class='splide__slide' data-splide-html-video='static/img/TrueCircle_3.mp4'><img src='static/img/TrueCircle_3.png'></li>"
                    ],
                    "In the first year, we launched a revolutionary hardware product that can be easily <b>retrofitted in just a few hours, with zero upfront cost</b> for our customers. Our system sends instant alerts for operational issues and verifies material purity with <b>95%+ accuracy in over 30 facilities</b> worldwide. This has led to increased trust in material quality and a direct increase in revenue per tonne. To further drive efficiency, TrueCircle also introduced Trade. In this online marketplace, Plant Managers can <b>buy and sell material verified by our AI vision system</b> using purity data for the first time."
                ],
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/TrueCircle_4.png'/></li>"
                    ],
                    "<b>My impact on the team:</b>\n<ul>\n  <li>Launched TrueCircle\u2019s MVP hardware and led the installation of an <b>initial pilot system at a UK recycling facility</b>.</li>\n  <li>Outlined roadmap for reducing failure rate. Implemented strategy and <b>led development of new hardware version</b>, eliminating key failure modes and saving \u00a31000s in maintenance.</li>\n  <li>Demonstrated technical leadership; established processes to hand over system installations to a 3rd-party supplier, <b>proving scalability</b>; a key requirement for TrueCircle\u2019s Series A.</li>\n</ul>"
                ]
            ]
        },
        "GoogleX": {
            "theme": "Experience",
            "hash": "GoogleX",
            "title": "Google X",
            "shorttitle": "Google X",
            "date": "2019",
            "subtitle": "Intern @ Google's Moonshot Factory",
            "duration": "Six Months Full-Time",
            "location": "Google X HQ, California",
            "thanks": "RM & RG.",
            "text1": "<a href=\"https://x.company/\"> Google X</a> is Google's experimental R&D facility. X's 'moonshot' approach to engineering explores ambitious high risk, high reward projects. The goal is to find <b>innovative solutions to some of the world's biggest problems</b> [climate change, energy, health, transportation etc.]. By taking a radical approach to problem-solving and pushing the boundaries of tech, Google X <i>aims</i> to make a positive impact on the world.",
            "text2": "During the six-month placement, I collaborated with an early-stage team to evaluate the feasibility of a <b>novel sensor technology</b>. As the team's software dev, I built the data pipeline, from sensor interrogation to cloud upload for machine learning. I co-designed a custom PCB, resulting in our first portable device with improved features, including a <b>4x size reduction</b> [same number of sensors], modular <b>expandability of up to 8x, 2.5x higher sensor signal resolution</b>, and a portable battery-powered design with a user interface.",
            "text3": "Through my work with X, I filed two <a href=\"https://patents.google.com/?inventor=bennet+cobley&oq=bennet+cobley\">2 Patent Applications</a> as <b>primary author</b>, which are now in the public domain. The patent applications describe a gas sensing system consisting of multiple gas sensor modules, each containing several gas sensors specific to a set of target analytes. The system is designed to sample a test environment by selecting any subset of the modules to create combinations of gasses to <b>generate training data for a machine-learned model</b>. These gas sensors can be pre-sensitised to specific targets using with the addition of a camera module.",
            "text4": "The sensor team partnered with Google's Farming Robotics project, <a href=\"https://x.company/projects/mineral/\">Mineral</a>. I built the hardware and software integration to connect our sensors to the physical robot and to Mineral's <b>ROS robotics system</b>. The data was published to the ROS network in real-time; with the combined sensor readings and GPS information enabling <b>geo-located insights about the plant health and yield</b>.",
            "highlights": [
                "Championed and built a new hardware generation",
                "Worked alongisde Mineral, Google's Farming Robot",
                "Filed 2 <a href=\"https://patents.google.com/?inventor=bennet+cobley&oq=bennet+cobley\"> Patent Applications</a>"
            ],
            "media1": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/GoogleX_1.png'/></li>"
            ],
            "media2": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/GoogleX_2.png'/></li>"
            ],
            "media3": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/GoogleX_4.png'/></li>"
            ],
            "media4": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/GoogleX_3.png'/></li>"
            ],
            "body": [
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/GoogleX_1.png'/></li>"
                    ],
                    "<a href=\"https://x.company/\"> Google X</a> is Google's experimental R&D facility. X's 'moonshot' approach to engineering explores ambitious high risk, high reward projects. The goal is to find <b>innovative solutions to some of the world's biggest problems</b> [climate change, energy, health, transportation etc.]. By taking a radical approach to problem-solving and pushing the boundaries of tech, Google X <i>aims</i> to make a positive impact on the world."
                ],
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/GoogleX_2.png'/></li>"
                    ],
                    "During the six-month placement, I collaborated with an early-stage team to evaluate the feasibility of a <b>novel sensor technology</b>. As the team's software dev, I built the data pipeline, from sensor interrogation to cloud upload for machine learning. I co-designed a custom PCB, resulting in our first portable device with improved features, including a <b>4x size reduction</b> [same number of sensors], modular <b>expandability of up to 8x, 2.5x higher sensor signal resolution</b>, and a portable battery-powered design with a user interface."
                ],
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/GoogleX_4.png'/></li>"
                    ],
                    "Through my work with X, I filed two <a href=\"https://patents.google.com/?inventor=bennet+cobley&oq=bennet+cobley\">2 Patent Applications</a> as <b>primary author</b>, which are now in the public domain. The patent applications describe a gas sensing system consisting of multiple gas sensor modules, each containing several gas sensors specific to a set of target analytes. The system is designed to sample a test environment by selecting any subset of the modules to create combinations of gasses to <b>generate training data for a machine-learned model</b>. These gas sensors can be pre-sensitised to specific targets using with the addition of a camera module."
                ],
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/GoogleX_3.png'/></li>"
                    ],
                    "The sensor team partnered with Google's Farming Robotics project, <a href=\"https://x.company/projects/mineral/\">Mineral</a>. I built the hardware and software integration to connect our sensors to the physical robot and to Mineral's <b>ROS robotics system</b>. The data was published to the ROS network in real-time; with the combined sensor readings and GPS information enabling <b>geo-located insights about the plant health and yield</b>."
                ]
            ]
        },
        "Dyson": {
            "theme": "Experience",
            "hash": "Dyson",
            "title": "Dyson",
            "shorttitle": "Dyson",
            "date": "2018",
            "subtitle": "Intern @ Dyson [New Product Development]",
            "duration": "Three Months Full-Time",
            "location": "Dyson HQ, Malmesbury",
            "thanks": "SH et al.",
            "text1": "A paid internship in <a href=\"https://careers.dyson.com/en-gb/what-you-can-do/engineer/new-product-innovation/\">Dyson's New Product Development</a> team. This project sharpened my <b>digital and physical prototyping abilities</b>, but has inspired me to seek out faster, more entrepreneurial working environments.",
            "text2": "I addressed a design challenge related to an unreleased product. Taking ownership of the part design process from <b>concept generation to design for manufacture</b>, I presented four solutions across various engineering risk levels, from quick fixes to comprehensive solutions that reimagined user interaction challenges. <b>Offered return role</b> at Dyson upon Graduation.",
            "highlights": [
                "Introduction to Dyson's engineering process",
                "Ownership of feature on unreleased product",
                "Offered return role upon graduation"
            ],
            "media1": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/Dyson_1.png'/></li>"
            ],
            "media2": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/Dyson_2.png'/></li>"
            ],
            "body": [
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/Dyson_1.png'/></li>"
                    ],
                    "A paid internship in <a href=\"https://careers.dyson.com/en-gb/what-you-can-do/engineer/new-product-innovation/\">Dyson's New Product Development</a> team. This project sharpened my <b>digital and physical prototyping abilities</b>, but has inspired me to seek out faster, more entrepreneurial working environments."
                ],
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/Dyson_2.png'/></li>"
                    ],
                    "I addressed a design challenge related to an unreleased product. Taking ownership of the part design process from <b>concept generation to design for manufacture</b>, I presented four solutions across various engineering risk levels, from quick fixes to comprehensive solutions that reimagined user interaction challenges. <b>Offered return role</b> at Dyson upon Graduation."
                ]
            ]
        },
        "Brompton": {
            "theme": "Experience",
            "hash": "Brompton",
            "title": "Brompton",
            "shorttitle": "Brompton",
            "date": "2017",
            "subtitle": "Intern @ Brompton Bicycle",
            "duration": "Three Months Full-Time",
            "location": "Brompton HQ, London",
            "thanks": "WCS & WBA.",
            "text1": "A paid internship at <a href=\"https://www.brompton.com/\">Brompton Bicycle Ltd</a>. I joined a live project team challenged with developing a <b>new Brompton product</b>. As a group of three interns, we began with a blank sheet of paper and concluded with three <b>fully ridable (and foldable) prototype bikes</b> in just three months. This project kick-started my computational design and hands-on workshop skillset.",
            "text2": "The CEO was highly complimentary of our work, and the project was <b>approved for commercialisation</b> (currently confidential). I am told the product is still in development and will be released 'soon'. When released, it will be Brompton's <b>first new core product line in 40+ years</b>.",
            "highlights": [
                "Collaborated as part of an all-intern team",
                "Challenged to redesign iconic Brompton product",
                "Fabricated 3 prototype bikes in just 3 months"
            ],
            "media1": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/Brompton_1.png'/></li>"
            ],
            "media2": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/Brompton_2.png'/></li>"
            ],
            "body": [
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/Brompton_1.png'/></li>"
                    ],
                    "A paid internship at <a href=\"https://www.brompton.com/\">Brompton Bicycle Ltd</a>. I joined a live project team challenged with developing a <b>new Brompton product</b>. As a group of three interns, we began with a blank sheet of paper and concluded with three <b>fully ridable (and foldable) prototype bikes</b> in just three months. This project kick-started my computational design and hands-on workshop skillset."
                ],
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/Brompton_2.png'/></li>"
                    ],
                    "The CEO was highly complimentary of our work, and the project was <b>approved for commercialisation</b> (currently confidential). I am told the product is still in development and will be released 'soon'. When released, it will be Brompton's <b>first new core product line in 40+ years</b>."
                ]
            ]
        }
    },
    "Education": {
        "Imperial": {
            "theme": "Education",
            "hash": "Imperial",
            "title": "Imperial College",
            "shorttitle": "Imperial",
            "date": "2020",
            "subtitle": "Design Engineering Master's Degree",
            "duration": "Four Years Full-Time",
            "location": "Dyson School of Design Engineering",
            "thanks": "WB et al.",
            "text1": "The <a href=\"https://www.imperial.ac.uk/design-engineering/\">Dyson School of Design Engineering</a> is the newest engineering department at Imperial College London. Design Engineering is a <b>highly creative discipline</b> that builds diverse skillsets across product development, technical innovation, user-centred design, and enterprise. The degree introduces a range of fundamental design and engineering topics, encouraging 'T-shaped' skillsets. I specialised in <b>robotics, physical computing and technical product development</b>. Through the degree, I found a love for building new things to solve hard problems.",
            "text2": "Demonstrated academic excellence over the 4-year degree, achieving the <b>highest overall degree result of the 2020 class</b> and placing on the Dean\u2019s List for Academic Excellence in '18/'19/'20 (top 10% of year). Robotics Group project team were awarded an <b>international robotics prize</b> at IROS 2022 for the <a href='https://iros2022.org/2022/10/30/award-winners/'>Best Application Paper</a>, for our work on a <a href=\"#Percussion\">medical percussion device</a>.",
            "highlights": [
                "Awarded Head of School Achievement Prize '20",
                "Dean\u2019s List for Academic Excellence '18/'19/'20",
                "IROS 2022 <a href='#Percussion'>Best Application Paper</a>"
            ],
            "media1": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/Imperial_1.png'/></li>"
            ],
            "media2": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/Imperial_2.png'/></li>"
            ],
            "body": [
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/Imperial_1.png'/></li>"
                    ],
                    "The <a href=\"https://www.imperial.ac.uk/design-engineering/\">Dyson School of Design Engineering</a> is the newest engineering department at Imperial College London. Design Engineering is a <b>highly creative discipline</b> that builds diverse skillsets across product development, technical innovation, user-centred design, and enterprise. The degree introduces a range of fundamental design and engineering topics, encouraging 'T-shaped' skillsets. I specialised in <b>robotics, physical computing and technical product development</b>. Through the degree, I found a love for building new things to solve hard problems."
                ],
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/Imperial_2.png'/></li>"
                    ],
                    "Demonstrated academic excellence over the 4-year degree, achieving the <b>highest overall degree result of the 2020 class</b> and placing on the Dean\u2019s List for Academic Excellence in '18/'19/'20 (top 10% of year). Robotics Group project team were awarded an <b>international robotics prize</b> at IROS 2022 for the <a href='https://iros2022.org/2022/10/30/award-winners/'>Best Application Paper</a>, for our work on a <a href=\"#Percussion\">medical percussion device</a>."
                ]
            ]
        }
    },
    "Publications": {
        "Percussion": {
            "theme": "Publications",
            "hash": "Percussion",
            "title": "Medical Percussion",
            "shorttitle": "Percussion",
            "date": "2020",
            "subtitle": "Robotics Research \nGroup Project",
            "duration": "Three Months Part-Time",
            "location": "MORPH Robotics Lab Imperial College London",
            "thanks": "PZQ/OT/YT/TN.",
            "text1": "<b>What is Percussion?</b> Medical percussion involves tapping the chest, back, and abdomen to assess the condition of underlying tissues based on the resulting acoustic response. <b>Despite its frequent use in medical diagnosis, percussion dynamics are not fully understood.</b> Experienced practitioners modify the percussion force and impulse by adjusting the stiffness in their elbow and wrist joints, but the correlation between these adjustments and the acoustic response remains underexplored. This project explored how robotics and ML could help standardise medical percussion examinations.",
            "text2": "Our Robotics Project Group introduced a <b>novel robotic percussion device</b> designed to imitate the human percussion technique through a two-degree-of-freedom linkage mechanism with adjustable joint stiffness. The force profile of a medical student performing percussion was captured and used to inform the simulation of a mathematical model of the mechanism in MATLAB (above). This allowed for identifying the <b>optimal parameters to build a hardware prototype</b>. The device was evaluated on a silicone phantom tissue model, demonstrating a <b>force profile comparable to that of a human performer</b>, with reduced variability between successive percussion actions.",
            "text3": "I contributed to the <b>development and analysis of the initial robotic device</b>. Teammate Oliver Thompson outlines the device in the presentation below. Oli's presentation was awarded Best Presentation overall at IROS RoPat20 Robot-Assisted Training For Primary Care Workshop.",
            "text4": "<b>My colleagues continued researching the topic after our graduation</b>. In their first experiment, the device used spectro-temporal analysis with 1-D Continuous Wavelet Transform (CWT) to identify hard nodules resembling lipomas in silicone phantom tissue. In their second experiment, Gaussian Mixture Modelling (GMM) and Neural Network (NN) predictive models were used to classify composite phantom tissue of varying density and thickness. The proposed device and methods achieved up to 97.5% accuracy in the classification of phantoms, indicating the potential for robotic solutions to <b>standardise and improve the accuracy of percussion</b> diagnostic procedures.  This paper was accepted for publication in <a href=\"https://ieeexplore.ieee.org/document/9830846/\">IEEE RA-L</a>.",
            "text5": "Pilar Zhang Qiu presented the paper at IROS2022 in Kyoto, Japan. We were thrilled to be awarded the <a href=\"https://iros2022.org/2022/10/30/award-winners/\">Best Application Paper Award</a>. This was all <b>thanks to my wonderful colleagues</b> Pilar Zhang Qiu, Jacob Tan, Oliver Thompson, and our supervisor, Prof Thrishantha Nanayakkara.",
            "highlights": [
                "Awarded Best Application Paper at <a href=\"https://iros2022.org/2022/10/30/award-winners/\">IROS 2022</a>",
                "Accepted for publication in <a href=\"https://ieeexplore.ieee.org/document/9830846/\">IEEE RA-L</a> ",
                "Published in <a href=\"https://www.imperial.ac.uk/news/242295/imperial-engineering-students-awarded-international-robotics/\">Imperial Newsletter</a>"
            ],
            "media1": [
                "<li class='splide__slide' data-splide-html-video='static/img/Percussion_1.mp4'><img src='static/img/Percussion_1.png'></li>"
            ],
            "media2": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/Percussion_2.png'/></li>"
            ],
            "media3": [
                "<li class='splide__slide' data-splide-html-video='static/img/Percussion_3.mp4'><img src='static/img/Percussion_3.png'></li>"
            ],
            "media4": [
                "<li class='splide__slide' data-splide-youtube='https://www.youtube.com/watch?v=fW7HsbtPrFo'><img src='static/img/fW7HsbtPrF.png'></li>"
            ],
            "media5": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/Percussion_4.png'/></li>"
            ],
            "body": [
                [
                    [
                        "<li class='splide__slide' data-splide-html-video='static/img/Percussion_1.mp4'><img src='static/img/Percussion_1.png'></li>"
                    ],
                    "<b>What is Percussion?</b> Medical percussion involves tapping the chest, back, and abdomen to assess the condition of underlying tissues based on the resulting acoustic response. <b>Despite its frequent use in medical diagnosis, percussion dynamics are not fully understood.</b> Experienced practitioners modify the percussion force and impulse by adjusting the stiffness in their elbow and wrist joints, but the correlation between these adjustments and the acoustic response remains underexplored. This project explored how robotics and ML could help standardise medical percussion examinations."
                ],
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/Percussion_2.png'/></li>"
                    ],
                    "Our Robotics Project Group introduced a <b>novel robotic percussion device</b> designed to imitate the human percussion technique through a two-degree-of-freedom linkage mechanism with adjustable joint stiffness. The force profile of a medical student performing percussion was captured and used to inform the simulation of a mathematical model of the mechanism in MATLAB (above). This allowed for identifying the <b>optimal parameters to build a hardware prototype</b>. The device was evaluated on a silicone phantom tissue model, demonstrating a <b>force profile comparable to that of a human performer</b>, with reduced variability between successive percussion actions."
                ],
                [
                    [
                        "<li class='splide__slide' data-splide-html-video='static/img/Percussion_3.mp4'><img src='static/img/Percussion_3.png'></li>"
                    ],
                    "I contributed to the <b>development and analysis of the initial robotic device</b>. Teammate Oliver Thompson outlines the device in the presentation below. Oli's presentation was awarded Best Presentation overall at IROS RoPat20 Robot-Assisted Training For Primary Care Workshop."
                ],
                [
                    [
                        "<li class='splide__slide' data-splide-youtube='https://www.youtube.com/watch?v=fW7HsbtPrFo'><img src='static/img/fW7HsbtPrF.png'></li>"
                    ],
                    "<b>My colleagues continued researching the topic after our graduation</b>. In their first experiment, the device used spectro-temporal analysis with 1-D Continuous Wavelet Transform (CWT) to identify hard nodules resembling lipomas in silicone phantom tissue. In their second experiment, Gaussian Mixture Modelling (GMM) and Neural Network (NN) predictive models were used to classify composite phantom tissue of varying density and thickness. The proposed device and methods achieved up to 97.5% accuracy in the classification of phantoms, indicating the potential for robotic solutions to <b>standardise and improve the accuracy of percussion</b> diagnostic procedures.  This paper was accepted for publication in <a href=\"https://ieeexplore.ieee.org/document/9830846/\">IEEE RA-L</a>."
                ],
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/Percussion_4.png'/></li>"
                    ],
                    "Pilar Zhang Qiu presented the paper at IROS2022 in Kyoto, Japan. We were thrilled to be awarded the <a href=\"https://iros2022.org/2022/10/30/award-winners/\">Best Application Paper Award</a>. This was all <b>thanks to my wonderful colleagues</b> Pilar Zhang Qiu, Jacob Tan, Oliver Thompson, and our supervisor, Prof Thrishantha Nanayakkara."
                ]
            ]
        },
        "OnionBot": {
            "theme": "Publications",
            "hash": "OnionBot",
            "title": "OnionBot",
            "shorttitle": "OnionBot",
            "date": "2020",
            "subtitle": "[Open Source] Master's Thesis",
            "duration": "One Year Part-Time",
            "location": "Imperial College London",
            "thanks": "DB.",
            "text1": "OnionBot is a robotic kitchen assistant designed to <b>automate routine pan-cooking tasks, freeing you up to focus on more creative aspects of cooking</b>. OnionBot was born from a desire for a robot that can soften onions while I work on other ingredients. The first OnionBot prototype combines machine vision and hobbyist electronics to showcase its ability to <b>cook a pasta and tomato sauce recipe autonomously</b>. I designed this project to build my skillset in Python algorithm and interface design and gain an understanding of ML at a prototype level. View the Master's Thesis on <a href=\"https://arxiv.org/pdf/2011.05039.pdf\">Arxiv</a>.",
            "text2": "Automation technology improves the work environment in the food industry reducing the physical and cognitive demands on workers. This tech could also augment home cooking by <b>reducing errors and providing decision-making support</b> to busy parents and professionals. However, designing automation technology for home kitchens is a unique challenge, requiring versatile tools instead of specialised machines. While robot arms can replicate human-kitchen interaction, they are too large and costly for home use. Cameras can detect a wide range of cooking information, but there are currently no datasets for training cooking image classification algorithms. With OnionBot, I explored <b>combining industrial automation and machine vision</b> to create a simple robot that can fit on a kitchen countertop.",
            "text3": "OnionBot focuses on automating pan-cooking tasks. A Raspberry Pi-powered camera and thermal camera are mounted above the stove to monitor the cooking progress. The servo motor automatically adjusts the power setting of the induction stove. The project's objective is to provide <b>automation without adding excessive complexity</b>; instead of replacing the chef, OnionBot empowers them with multitasking capabilities. The human provides the 'actuation' enhanced by a touchscreen interface called \"sous-chef\" that offers instructions, reminders, and alerts. OnionBot takes care of the pan, enabling the chef to concentrate on culinary creativity. This <b>human-centred approach</b> is a novel concept in cooking robotics research.",
            "text4": "Food image classification research has shown poor results in real-world scenarios due to the complex and variable nature of food images. To address these perception challenges in cooking, OnionBot introduces two innovations. Firstly, the <b>fixed camera view above the stove provides a consistent environment</b> for capturing images. Secondly, instead of pursuing a general classification approach, OnionBot adopts a milestone-based method where <b>only key cooking events, or milestones, are labelled</b> for a single recipe. This significantly simplifies the perception challenge by reducing the number of classes each classification model needs to identify (from 1000s to 10s). OnionBot includes a <b>labelling interface</b> for creating labelled cooking image datasets by clicking along with each milestone while cooking. Google AutoML is used for streamlined model training, enabling new recipe models to be trained with a few clicks.",
            "text5": "This prototype showcases the potential for automation in home cooking but requires large training datasets to succeed. I propose that a <b>fleet learning network</b> of OnionBot devices could crowd-source large labelled pan-cooking image databases. The fleet-generated dataset, including rich metadata, could drive new research into cooking with AI. <b>I open-sourced OnionBot</b> to encourage further research into home cooking automation. The project has generated a lot of interest, including from Texas-based Hill Yu who built an OnionBot prototype (pictured above) called <a href=\"https://www.kitchenautomatique.com/\">Kitchen Automatique</a> and fundraised $40K to <b>commercialise the idea</b>. Wishing Kitchen Automatique the best of luck!",
            "highlights": [
                "Masters Thesis made available on <a href=\"https://arxiv.org/pdf/2011.05039.pdf\">Arxiv</a>",
                "Code open-sourced on <a href=\"https://github.com/onionbot \">GitHub</a>",
                "Project featured in <a href=\"static/img/MagPi101.pdf\">RPi Official Magazine</a>"
            ],
            "media1": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/OnionBot_1a.png'/></li>",
                "<li class='splide__slide'><img data-splide-lazy='static/img/OnionBot_1b.png'/></li>"
            ],
            "media2": [
                "<li class='splide__slide' data-splide-youtube='https://www.youtube.com/watch?v=W4utRCyo5C4'><img src='static/img/W4utRCyo5C4.png'></li>"
            ],
            "media3": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/OnionBot_3.png'/></li>"
            ],
            "media4": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/OnionBot_4a.png'/></li>",
                "<li class='splide__slide'><img data-splide-lazy='static/img/OnionBot_4b.png'/></li>"
            ],
            "media5": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/OnionBot_5.png'/></li>"
            ],
            "body": [
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/OnionBot_1a.png'/></li>",
                        "<li class='splide__slide'><img data-splide-lazy='static/img/OnionBot_1b.png'/></li>"
                    ],
                    "OnionBot is a robotic kitchen assistant designed to <b>automate routine pan-cooking tasks, freeing you up to focus on more creative aspects of cooking</b>. OnionBot was born from a desire for a robot that can soften onions while I work on other ingredients. The first OnionBot prototype combines machine vision and hobbyist electronics to showcase its ability to <b>cook a pasta and tomato sauce recipe autonomously</b>. I designed this project to build my skillset in Python algorithm and interface design and gain an understanding of ML at a prototype level. View the Master's Thesis on <a href=\"https://arxiv.org/pdf/2011.05039.pdf\">Arxiv</a>."
                ],
                [
                    [
                        "<li class='splide__slide' data-splide-youtube='https://www.youtube.com/watch?v=W4utRCyo5C4'><img src='static/img/W4utRCyo5C4.png'></li>"
                    ],
                    "Automation technology improves the work environment in the food industry reducing the physical and cognitive demands on workers. This tech could also augment home cooking by <b>reducing errors and providing decision-making support</b> to busy parents and professionals. However, designing automation technology for home kitchens is a unique challenge, requiring versatile tools instead of specialised machines. While robot arms can replicate human-kitchen interaction, they are too large and costly for home use. Cameras can detect a wide range of cooking information, but there are currently no datasets for training cooking image classification algorithms. With OnionBot, I explored <b>combining industrial automation and machine vision</b> to create a simple robot that can fit on a kitchen countertop."
                ],
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/OnionBot_3.png'/></li>"
                    ],
                    "OnionBot focuses on automating pan-cooking tasks. A Raspberry Pi-powered camera and thermal camera are mounted above the stove to monitor the cooking progress. The servo motor automatically adjusts the power setting of the induction stove. The project's objective is to provide <b>automation without adding excessive complexity</b>; instead of replacing the chef, OnionBot empowers them with multitasking capabilities. The human provides the 'actuation' enhanced by a touchscreen interface called \"sous-chef\" that offers instructions, reminders, and alerts. OnionBot takes care of the pan, enabling the chef to concentrate on culinary creativity. This <b>human-centred approach</b> is a novel concept in cooking robotics research."
                ],
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/OnionBot_4a.png'/></li>",
                        "<li class='splide__slide'><img data-splide-lazy='static/img/OnionBot_4b.png'/></li>"
                    ],
                    "Food image classification research has shown poor results in real-world scenarios due to the complex and variable nature of food images. To address these perception challenges in cooking, OnionBot introduces two innovations. Firstly, the <b>fixed camera view above the stove provides a consistent environment</b> for capturing images. Secondly, instead of pursuing a general classification approach, OnionBot adopts a milestone-based method where <b>only key cooking events, or milestones, are labelled</b> for a single recipe. This significantly simplifies the perception challenge by reducing the number of classes each classification model needs to identify (from 1000s to 10s). OnionBot includes a <b>labelling interface</b> for creating labelled cooking image datasets by clicking along with each milestone while cooking. Google AutoML is used for streamlined model training, enabling new recipe models to be trained with a few clicks."
                ],
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/OnionBot_5.png'/></li>"
                    ],
                    "This prototype showcases the potential for automation in home cooking but requires large training datasets to succeed. I propose that a <b>fleet learning network</b> of OnionBot devices could crowd-source large labelled pan-cooking image databases. The fleet-generated dataset, including rich metadata, could drive new research into cooking with AI. <b>I open-sourced OnionBot</b> to encourage further research into home cooking automation. The project has generated a lot of interest, including from Texas-based Hill Yu who built an OnionBot prototype (pictured above) called <a href=\"https://www.kitchenautomatique.com/\">Kitchen Automatique</a> and fundraised $40K to <b>commercialise the idea</b>. Wishing Kitchen Automatique the best of luck!"
                ]
            ]
        }
    },
    "Projects": {
        "Dome": {
            "theme": "Projects",
            "hash": "Dome",
            "title": "Geodesic Dome",
            "shorttitle": "Dome",
            "date": "2022",
            "subtitle": "Personal Project",
            "duration": "Evenings & Weekends",
            "location": "Home",
            "thanks": "ZK et al.",
            "text1": "After <a href=\"#FarmBot\">FarmBot</a>, we built a greenhouse dome for propagation and overwintering vegetable plants.",
            "text2": "More details coming soon.",
            "highlights": [
                "Polyhedron: Icosahedron",
                "Frequency: 2",
                "Subdivision class: I",
                "3/4 Sphere (flat base)"
            ],
            "media1": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/Dome_1.png'/></li>"
            ],
            "media2": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/Dome_2.png'/></li>"
            ],
            "body": [
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/Dome_1.png'/></li>"
                    ],
                    "After <a href=\"#FarmBot\">FarmBot</a>, we built a greenhouse dome for propagation and overwintering vegetable plants."
                ],
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/Dome_2.png'/></li>"
                    ],
                    "More details coming soon."
                ]
            ]
        },
        "Inky": {
            "theme": "Projects",
            "hash": "Inky",
            "title": "Inky for Spotify",
            "shorttitle": "Inky",
            "date": "2021",
            "subtitle": "Personal Project",
            "duration": "Evenings & Weekends",
            "location": "Home",
            "thanks": "TC.",
            "text1": "Use a Raspberry Pi to display album art for your current Spotify listens on a 7-colour ePaper display. Designed for use with an Inky Impression 7 colour ePaper display. The ePaper display transitions bring the album art to life and doesn't require power to maintain the image! Check it out on <a href=\"https://github.com/tomcobley/inky-spotify\">GitHub</a>",
            "highlights": [
                "View your album art in a beautiful e-ink frame!",
                "Check the project out on <a href=\"https://github.com/tomcobley/inky-spotify\">GitHub</a>"
            ],
            "media1": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/Inky_2.gif'/></li>"
            ],
            "body": [
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/Inky_2.gif'/></li>"
                    ],
                    "Use a Raspberry Pi to display album art for your current Spotify listens on a 7-colour ePaper display. Designed for use with an Inky Impression 7 colour ePaper display. The ePaper display transitions bring the album art to life and doesn't require power to maintain the image! Check it out on <a href=\"https://github.com/tomcobley/inky-spotify\">GitHub</a>"
                ]
            ]
        },
        "FarmBot": {
            "theme": "Projects",
            "hash": "FarmBot",
            "title": "FarmBot",
            "shorttitle": "FarmBot",
            "date": "2021",
            "subtitle": "Personal Project",
            "duration": "Evenings & Weekends",
            "location": "Home",
            "thanks": "ZK et al.",
            "text1": "<a href=\"https://farm.bot/\">FarmBot</a> is an <b>open-source, automated farming robot</b> for growing food using precision agriculture techniques developed by a team in California. Changeable tool heads on a CNC cartesian gantry system allow FarmBot to sow seeds, water plants and destroy weeds automatically.",
            "text2": "This was a lockdown project motivated by the desire to be <b>more self-sustainable</b> by growing our own food. While FarmBot probably won't save money or time, net, over its lifetime, it did get us into vegetable growing!",
            "text3": "We had a great crop in the first year (pictured: giant lettuce), but 90% of the credit goes to the humans looking after FarmBot.",
            "highlights": [
                "No more sowing!",
                "No more watering!",
                "No more weeding!"
            ],
            "media1": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/FarmBot_1a.png'/></li>",
                "<li class='splide__slide'><img data-splide-lazy='static/img/FarmBot_1b.png'/></li>"
            ],
            "media2": [
                "<li class='splide__slide' data-splide-html-video='static/img/Farmbot_2a.mp4'><img src='static/img/Farmbot_2a.png'></li>",
                "<li class='splide__slide' data-splide-html-video='static/img/Farmbot_2b.mp4'><img src='static/img/Farmbot_2b.png'></li>"
            ],
            "media3": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/FarmBot_3a.png'/></li>",
                "<li class='splide__slide'><img data-splide-lazy='static/img/FarmBot_3b.png'/></li>"
            ],
            "body": [
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/FarmBot_1a.png'/></li>",
                        "<li class='splide__slide'><img data-splide-lazy='static/img/FarmBot_1b.png'/></li>"
                    ],
                    "<a href=\"https://farm.bot/\">FarmBot</a> is an <b>open-source, automated farming robot</b> for growing food using precision agriculture techniques developed by a team in California. Changeable tool heads on a CNC cartesian gantry system allow FarmBot to sow seeds, water plants and destroy weeds automatically."
                ],
                [
                    [
                        "<li class='splide__slide' data-splide-html-video='static/img/Farmbot_2a.mp4'><img src='static/img/Farmbot_2a.png'></li>",
                        "<li class='splide__slide' data-splide-html-video='static/img/Farmbot_2b.mp4'><img src='static/img/Farmbot_2b.png'></li>"
                    ],
                    "This was a lockdown project motivated by the desire to be <b>more self-sustainable</b> by growing our own food. While FarmBot probably won't save money or time, net, over its lifetime, it did get us into vegetable growing!"
                ],
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/FarmBot_3a.png'/></li>",
                        "<li class='splide__slide'><img data-splide-lazy='static/img/FarmBot_3b.png'/></li>"
                    ],
                    "We had a great crop in the first year (pictured: giant lettuce), but 90% of the credit goes to the humans looking after FarmBot."
                ]
            ]
        },
        "Campervan": {
            "theme": "Projects",
            "hash": "Campervan",
            "title": "Campervan conversion",
            "shorttitle": "Campervan",
            "date": "2020",
            "subtitle": "Personal Project",
            "duration": "Six Months Full-Time",
            "location": "Home",
            "thanks": "CW, HB et al.",
            "text1": "Campervan conversion personal project with friends during our year off. We took an unusual approach to typical van conversions, opting for an aluminium extrusion frame wrapped in lightweight plywood. Sleeping four comfortably meant thinking outside the box. We had three design goals:\n<ul>\n  <li>Four berths and four seats, comfortably.</li>\n  <li>Switching from day to night mode should take seconds, not minutes.</li>\n  <li>We won't get it 100% right first time, so everything should be removable</li>\n</ul>",
            "text2": "We created a first-of-its-kind (as far as we know) bed sliding mechanism to allow us to include four berths and four seats, comfortably. Check out the assembly timelapse in the video below!",
            "text3": "For power, I built a fully off-grid solar system, so that the van never needs to be plugged in. I learnt how to spec solar panels, controllers etc. through online tutorials and assembled the system myself (see timelapse above). The specs:\n\n<ul>\n  <li>1200W Inverter for 240V mains power</li>\n  <li>100Ah 12V Lithium battery</li>\n  <li>440W Domestic Solar Panel</li>\n  <li>30A charger from vehicle alternator</li>\n  <li>Bluetooth connectivity to phone application</li>\n  <li>LED lights, 12V phone chargers, fridge, water pump etc.</li>\n</ul>\n\nBuilding a campervan was fulfilling, but way more work than I ever imagined. Proceed with caution!",
            "highlights": [
                "Personal project with friends during our year off",
                "Unique custom-designed bed mechanism",
                "All DIY: wood/metalwork, electrics and plumbing"
            ],
            "media1": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/Campervan_1.png'/></li>"
            ],
            "media2": [
                "<li class='splide__slide'><img data-splide-lazy='static/img/Campervan_2.png'/></li>"
            ],
            "media3": [
                "<li class='splide__slide' data-splide-youtube='https://www.youtube.com/watch?v=Ocdxqeg01c4'><img src='static/img/Ocdxqeg01c4.png'></li>"
            ],
            "body": [
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/Campervan_1.png'/></li>"
                    ],
                    "Campervan conversion personal project with friends during our year off. We took an unusual approach to typical van conversions, opting for an aluminium extrusion frame wrapped in lightweight plywood. Sleeping four comfortably meant thinking outside the box. We had three design goals:\n<ul>\n  <li>Four berths and four seats, comfortably.</li>\n  <li>Switching from day to night mode should take seconds, not minutes.</li>\n  <li>We won't get it 100% right first time, so everything should be removable</li>\n</ul>"
                ],
                [
                    [
                        "<li class='splide__slide'><img data-splide-lazy='static/img/Campervan_2.png'/></li>"
                    ],
                    "We created a first-of-its-kind (as far as we know) bed sliding mechanism to allow us to include four berths and four seats, comfortably. Check out the assembly timelapse in the video below!"
                ],
                [
                    [
                        "<li class='splide__slide' data-splide-youtube='https://www.youtube.com/watch?v=Ocdxqeg01c4'><img src='static/img/Ocdxqeg01c4.png'></li>"
                    ],
                    "For power, I built a fully off-grid solar system, so that the van never needs to be plugged in. I learnt how to spec solar panels, controllers etc. through online tutorials and assembled the system myself (see timelapse above). The specs:\n\n<ul>\n  <li>1200W Inverter for 240V mains power</li>\n  <li>100Ah 12V Lithium battery</li>\n  <li>440W Domestic Solar Panel</li>\n  <li>30A charger from vehicle alternator</li>\n  <li>Bluetooth connectivity to phone application</li>\n  <li>LED lights, 12V phone chargers, fridge, water pump etc.</li>\n</ul>\n\nBuilding a campervan was fulfilling, but way more work than I ever imagined. Proceed with caution!"
                ]
            ]
        }
    }
}