tag,title,shorttitle,date,subtitle,highlights,duration,location,thanks,media1,text1,media2,text2,media3,text3,media4,text4,media5,text5
TrueCircle,TrueCircle AI,TrueCircle AI,2021+,Design Engineer @ Early-Stage Startup,"First full-time hardware engineer
Launched MVP product in UK facility
Implemented roadmap to outsource site work",1 Year+ full-time,"TrueCircle HQ, London",PH et al.,<img src='static/img/TrueCircle_1.png'/>,"<a href='https://www.truecircle.ai/'>TrueCircle AI</a> is a climate-tech startup developing ground-breaking computer vision hardware that enables recycling facilities to recover valuable material more effectively and sell material more efficiently. We retrofit industrial cameras above conveyor belts to capture continuous footage of material streams. Our state-of-the-art model calculates composition by weight in real-time, to a 95%+ accuracy. We’ve built industry-leading dashboards that empower facilites to run more efficiently, preventing recyclable material from going to landfill.","<img src='static/img/TrueCircle_2a.png'/>
<img src='static/img/TrueCircle_2b.png'/>
<img src='static/img/TrueCircle_2c.png'/>","TrueCircle partnered with UK facilites to investigate data-driven optimisation of recycling processes. A typical TrueCircle AI user is a Plant Manager who is preocupied with keeping unreliable equipment running, and doesn't have time to experiment with upgrades to improve profitability. Our users lacked any data to inform decisions on upgrading equipment, or calibrate the price of their recycled material. The existing players in the market couldn't offer a solution accurate enough to justify their time-consuming and costly setup process.","<video loop autoplay muted><source src=""static/img/TrueCircle_3.mp4"" type=""video/mp4"" /></video>","I joined as TrueCircle's first full-time hardware engineer. Over the past year+, we launched a product that can be retrofit in a few hours, with zero up-front hardware cost for our customers. We send instant alerts flagging operational issues, and we can verify material purity with 95+% accuracy in 30+ facilities internationally. Buyers now trust material quality, leading to a direct increase in revenue per tonne. TrueCircle has also launched Trade, an online marketplace that allows Plant Managers to buy and sell material verified by purity data from our AI vision system, for the first time.",<img src='static/img/TrueCircle_4.png'/>,"My responsibilities: Launched TrueCircle’s MVP hardware and led installation of our initial pilot system at a UK recycling facility. Outlined a roadmap for reducing failure rate. Implemented a strategy and led development of new hardware version, resulting in a 10x reduction in 12-month failure rate, saving £1000s in maintenance costs. Demonstrated technical leadership; designed and implemented processes to hand over system installations to a 3rd-party supplier, proving product scalability; a key requirement for TrueCircle’s upcoming Series A.",,
OnionBot,OnionBot,OnionBot,2020,Individual Project,Confident in Python algorithm and interface design. Good understanding of ML at a prototype level.,1 Year part-time,Imperial College London,DB,"<div class=""video-container""><iframe width=""560"" height=""315"" src=""https://www.youtube.com/embed/W4utRCyo5C4?controls=0"" frameborder=""0"" allow=""accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen ></iframe></div>","OnionBot is a robotic sous-chef that automates simple pan-cooking tasks, giving you multitasking superpowers that allow you to focus more on culinary creativity. The project was inspired by a vision for a robot that can soften the onions while you prepare the next ingredients. The first OnionBot prototype brings together machine vision and hobbyist electronics to demonstrate autonomous cooking of a pasta and tomato sauce recipe - check out the video below! In open sourcing OnionBot, I hope to inspire a community of collaborators and early adopters to continue to develop the vision.","<img src='static/img/OnionBot_2a.png'/>
<img src='static/img/OnionBot_2b.png'/>","Automation technology in the food industry reduces physical and cognitive demands on production line operators. Perhaps the same tech could also reduce errors and assist decision-making in home cooking? How might automation augment the cooking skills of busy parents and professionals, for example? Kitchens pose very different design engineering challenges to industry, however, as home cooking requires multi-purpose tools rather than specialised machines. Robot arms can mimic human-kitchen interaction, but these are too large and expensive to be feasible for home use. For multi-purpose sensing, cameras can detect a wide variety of cooking information, but there are currently no datasets for training cooking image classification algorithms. With OnionBot, I wanted to see if there was a way to integrate industry automation techniques and machine vision into a simple robot that fits on a countertop.","<img src='static/img/OnionBot_3a.png'/>
<img src='static/img/OnionBot_3b.png'/>","OnionBot tackles automation of pan cooking. The camera and thermal camera mounted above the stove track cooking progress, and data is processed by a Raspberry Pi. The servo motor automatically controls induction stove power setting. The goal of this project is automation without unnecessary complexity. After all, we are not replacing the chef but simply giving them multi-tasking superpowers! There is no actuator more flexible and dextrous than the human: a touch screen interface called ‘sous-chef’ provides instructions, reminders, and alerts. OnionBot takes care of the pan so that the chef can focus on culinary creativity. This human-in-the-loop approach is a first of its kind in cooking robotics research.",<img src='static/img/OnionBot_4.png'/>,"Food image classification research has reported poor real-world results; food images often have tricky-to-define features and a lot of environmental variation. A cooking device must tackle these perception problems. OnionBot introduces two improvements. The fixed stove-top camera view ensures a consistent environment. Researchers typically explore general classification, attempting to identify characteristics from 1000s of potential classes. OnionBot instead establishes a milestone-based approach, labelling only key events at which actions occur (milestones) for a single recipe. Each classification model must identify just 10s of classes, dramatically simplifying the perception challenge. As these datasets don’t currently exist, OnionBot includes an interface for easy creation of labelled datasets of cooking images. With the control panel you simply click along with each milestone as you cook, and labelled images are automatically uploaded to the cloud where they can be accessed by model training platforms. Training is streamlined using Google AutoML, allowing models to be trained for new recipes with just a few clicks.",<img src='static/img/OnionBot_5.png'/>,"This prototype demonstrates an initial proof-of-concept showing the possibilities of automation in home cooking, but large training datasets will be critical to success of machine vision systems. I propose that autonomous cooking should be approached in the same way that Tesla Motors approaches autonomous driving. Rolling out a ‘fleet’ of networked OnionBot devices would enable crowd-sourcing of massive labeled pan-cooking image databases. Large cooking image databases don’t currently exist. The OnionBot dataset (which would also include rich metadata on ingredients, temperature, recipes, corrective inputs, and so on) could enable new research into cooking with AI. OnionBot is open-sourced to encourage further research into home cooking automation. This project is perfect for makers and hobbyists, as it comprises off-the-shelf components and accessible code. Long term, a community of collaborators and early adopters could crowd-source: The massive cooking image dataset. A database of recipe vision models. Advanced deep learning functionality, beyond classification. New ‘product’ hardware design."