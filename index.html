<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta http-equiv="X-UA-Compatible" content="ie=edge" />
    <title>Ben Cobley</title>
    <link rel="stylesheet" href="style/style.css" />
    <link rel="stylesheet" href="style/splide/splide.min.css" />
  </head>
  <body>
    <script src="style/jquery.js"></script>
    <script src="style/splide/splide.min.js"></script>
    <script src="style/index.js"></script>
    <timeline-section>
      <timeline-homepage>
        <timeline-me
          ><a
            href="https://www.linkedin.com/in/bennetcobley/"
            target="_blank"
            rel="noopener noreferrer"
            ><img src="img/me.png" /></a
        ></timeline-me>
        <timeline-text>
          👋 Hey! I’m Ben. I am a technologist, engineer, & designer. I am
          currently working on game-changing tech for the recycling industry
          <a> &#64;TrueCircle AI</a>. Before that, I studied at Imperial College
          London, where, I developed <a>cooking robots</a> and a
          <a>tissue characterisation robot</a>, amongst other things! During the
          Design Engineering degree, I interned at Google X, Dyson, and
          Brompton. I got to work on some
          <a>great projects with great people</a>. In my free time, I love
          <a>building stuff with friends</a>. Interested in building new things
          / making a positive impact on earth? <a>Say hello!</a>.
        </timeline-text>
        <a href="#timeline-section1" class="Arrow"></a>
      </timeline-homepage>
    </timeline-section>

    <timeline-section>
      <timeline-left-column>
        <timeline-left-div>
          <timeline-short-title>TrueCircle AI</timeline-short-title>
          <timeline-date>2021+</timeline-date>
          <timeline-subtitle
            >Design Engineer @ Early-Stage Startup</timeline-subtitle
          >
          <timeline-highlights>
            <ul>
              <li>Launched MVP product in UK facility</li>
              <li>Developed 10x more reliable hardware</li>
              <li>Implemented roadmap to outsource site work</li>
            </ul></timeline-highlights
          >
          <timeline-duration>1 Year+ full-time</timeline-duration>
          <timeline-location>TrueCircle HQ, London</timeline-location>
          <timeline-thanks>PH et al.</timeline-thanks>
        </timeline-left-div>
      </timeline-left-column>
      <timeline-right-column>
        <timeline-right-div>
          <timeline-title>TrueCircle AI</timeline-title>
          <img src="img/TrueCircle_1.png" />
          <timeline-text>
            <a href="https://www.truecircle.ai/">TrueCircle AI</a> is a
            climate-tech startup developing ground-breaking computer vision
            hardware that enables recycling facilities to
            <b>recover valuable material more effectively</b> and sell material
            more efficiently. We retrofit industrial cameras above conveyor
            belts to capture continuous footage of material streams. Our
            state-of-the-art model calculates composition by weight in
            real-time, to a 95%+ accuracy. We’ve built industry-leading
            dashboards that empower facilites to run more efficiently,
            preventing recyclable material from going to landfill.
          </timeline-text>
          <div class="splide">
            <div class="splide__track">
              <ul class="splide__list">
                <li class="splide__slide">
                  <img src="img/TrueCircle_2a.png" />
                </li>
                <li class="splide__slide">
                  <img src="img/TrueCircle_2b.png" />
                </li>
                <li class="splide__slide">
                  <img src="img/TrueCircle_2c.png" />
                </li>
              </ul>
            </div>
          </div>
          <timeline-text>
            TrueCircle partnered with UK facilites to investigate data-driven
            optimisation of recycling processes. A typical TrueCircle AI user is
            a Plant Manager who is preocupied with keeping unreliable equipment
            running, and doesn't have time to experiment with upgrades to
            improve profitability. Our users lacked any data to inform decisions
            on upgrading equipment, or calibrate the price of their recycled
            material. The existing players in the market couldn't offer a
            solution accurate enough to justify their time-consuming and costly
            setup process.
          </timeline-text>
          <video loop autoplay muted>
            <source src="img/TrueCircle_3.mp4" type="video/mp4" />
          </video>
          <timeline-text>
            I joined as TrueCircle's first full-time hardware engineer. Over the
            past year+, we launched a product that can be retrofit in a few
            hours, with zero up-front hardware cost for our customers. We send
            instant alerts flagging operational issues, and we can verify
            material purity with 95+% accuracy in 30+ facilities
            internationally. Buyers now trust material quality, leading to a
            direct increase in revenue per tonne. TrueCircle has also launched
            Trade, an online marketplace that allows Plant Managers to buy and
            sell material verified by purity data from our AI vision system, for
            the first time.
          </timeline-text>
          <img src="img/TrueCircle_4.png" />
          <timeline-text>
            My responsibilities: Launched TrueCircle’s MVP hardware and led
            installation of our initial pilot system at a UK recycling facility.
            Outlined a roadmap for reducing failure rate. Implemented a strategy
            and led development of new hardware version, resulting in a 10x
            reduction in 12-month failure rate, saving £1000s in maintenance
            costs. Demonstrated technical leadership; designed and implemented
            processes to hand over system installations to a 3rd-party supplier,
            proving product scalability; a key requirement for TrueCircle’s
            upcoming Series A.
          </timeline-text>
        </timeline-right-div>
      </timeline-right-column>
    </timeline-section>

    <timeline-section>
      <timeline-left-column>
        <timeline-left-div>
          <timeline-short-title>OnionBot</timeline-short-title>
          <timeline-date>2020</timeline-date>
          <timeline-subtitle>Design & Build Master's Project</timeline-subtitle>
          <timeline-highlights>
            <ul>
              <li>OnionBot</li>
              <li>OnionBot</li>
              <li>OnionBot</li>
            </ul></timeline-highlights
          >
          <timeline-duration>1 Year part-time</timeline-duration>
          <timeline-location>Imperial College London</timeline-location>
          <timeline-thanks>DB</timeline-thanks>
        </timeline-left-div>
      </timeline-left-column>
      <timeline-right-column>
        <timeline-right-div>
          <timeline-title>OnionBot</timeline-title>
          <div class="video-container">
            <iframe
              width="560"
              height="315"
              src="https://www.youtube.com/embed/W4utRCyo5C4?controls=0"
              frameborder="0"
              allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
              allowfullscreen
            ></iframe>
          </div>
          <timeline-text>
            OnionBot is a robotic sous-chef that automates simple pan-cooking
            tasks, giving you multitasking superpowers that allow you to focus
            more on culinary creativity. The project was inspired by a vision
            for a robot that can soften the onions while you prepare the next
            ingredients. The first OnionBot prototype brings together machine
            vision and hobbyist electronics to demonstrate autonomous cooking of
            a pasta and tomato sauce recipe - check out the video below! In open
            sourcing OnionBot, I hope to inspire a community of collaborators
            and early adopters to continue to develop the vision.
          </timeline-text>
          <div class="splide">
            <div class="splide__track">
              <ul class="splide__list">
                <li class="splide__slide">
                  <img src="img/OnionBot_2a.png" />
                </li>
                <li class="splide__slide">
                  <img src="img/OnionBot_2b.png" />
                </li>
              </ul>
            </div>
          </div>
          <timeline-text>
            Automation technology in the food industry reduces physical and
            cognitive demands on production line operators. Perhaps the same
            tech could also reduce errors and assist decision-making in home
            cooking? How might automation augment the cooking skills of busy
            parents and professionals, for example? Kitchens pose very different
            design engineering challenges to industry, however, as home cooking
            requires multi-purpose tools rather than specialised machines. Robot
            arms can mimic human-kitchen interaction, but these are too large
            and expensive to be feasible for home use. For multi-purpose
            sensing, cameras can detect a wide variety of cooking information,
            but there are currently no datasets for training cooking image
            classification algorithms. With OnionBot, I wanted to see if there
            was a way to integrate industry automation techniques and machine
            vision into a simple robot that fits on a countertop.
          </timeline-text>

          <div class="splide">
            <div class="splide__track">
              <ul class="splide__list">
                <li class="splide__slide">
                  <img src="img/OnionBot_3a.png" />
                </li>
                <li class="splide__slide">
                  <img src="img/OnionBot_3b.png" />
                </li>
              </ul>
            </div>
          </div>
          <timeline-text>
            OnionBot tackles automation of pan cooking. The camera and thermal
            camera mounted above the stove track cooking progress, and data is
            processed by a Raspberry Pi. The servo motor automatically controls
            induction stove power setting. The goal of this project is
            automation without unnecessary complexity. After all, we are not
            replacing the chef but simply giving them multi-tasking superpowers!
            There is no actuator more flexible and dextrous than the human: a
            touch screen interface called ‘sous-chef’ provides instructions,
            reminders, and alerts. OnionBot takes care of the pan so that the
            chef can focus on culinary creativity. This human-in-the-loop
            approach is a first of its kind in cooking robotics research.
          </timeline-text>
          <img src="img/OnionBot_4.png" />
          <timeline-text>
            Food image classification research has reported poor real-world
            results; food images often have tricky-to-define features and a lot
            of environmental variation. A cooking device must tackle these
            perception problems. OnionBot introduces two improvements. The fixed
            stove-top camera view ensures a consistent environment. Researchers
            typically explore general classification, attempting to identify
            characteristics from 1000s of potential classes. OnionBot instead
            establishes a milestone-based approach, labelling only key events at
            which actions occur (milestones) for a single recipe. Each
            classification model must identify just 10s of classes, dramatically
            simplifying the perception challenge. As these datasets don’t
            currently exist, OnionBot includes an interface for easy creation of
            labelled datasets of cooking images. With the control panel you
            simply click along with each milestone as you cook, and labelled
            images are automatically uploaded to the cloud where they can be
            accessed by model training platforms. Training is streamlined using
            Google AutoML, allowing models to be trained for new recipes with
            just a few clicks.
          </timeline-text>
          <img src="img/OnionBot_5.png" />
          <timeline-text>
            This prototype demonstrates an initial proof-of-concept showing the
            possibilities of automation in home cooking, but large training
            datasets will be critical to success of machine vision systems. I
            propose that autonomous cooking should be approached in the same way
            that Tesla Motors approaches autonomous driving. Rolling out a
            ‘fleet’ of networked OnionBot devices would enable crowd-sourcing of
            massive labeled pan-cooking image databases. Large cooking image
            databases don’t currently exist. The OnionBot dataset (which would
            also include rich metadata on ingredients, temperature, recipes,
            corrective inputs, and so on) could enable new research into cooking
            with AI. OnionBot is open-sourced to encourage further research into
            home cooking automation. This project is perfect for makers and
            hobbyists, as it comprises off-the-shelf components and accessible
            code. Long term, a community of collaborators and early adopters
            could crowd-source: The massive cooking image dataset. A database of
            recipe vision models. Advanced deep learning functionality, beyond
            classification. New ‘product’ hardware design.
          </timeline-text>
        </timeline-right-div>
      </timeline-right-column>
    </timeline-section>

    <timeline-section>
      <timeline-footer>
        <timeline-text>
          &copy; Ben Cobley
          <script>
            document.write(new Date().getFullYear());
          </script>
          <br />
          Fork my template on
          <a href="https://github.com/bencobley/bencobley.github.io">GitHub</a>
          <br />
          Made with ❤️ from scratch in
          <a href="https://en.wikipedia.org/wiki/International_orange"
            >International Orange</a
          >
        </timeline-text>
      </timeline-footer>
    </timeline-section>
  </body>
</html>
